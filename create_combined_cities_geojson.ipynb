{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f958e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('c:\\\\Users\\\\larry\\\\Desktop\\\\Geoguessr ML Proj\\\\Geolocation-Project\\\\reverse_geocode3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd85d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import re \n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_all_worldcities = False\n",
    "should_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81993a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading city data from GeoNames cities500.txt...\n",
      "Reading natural_earth_data/cities500.txt ...\n",
      "Loaded 215735 entries from GeoNames.\n",
      "\n",
      "--- Loading Admin Name Mappings ---\n",
      "Loading Admin1 names from natural_earth_data/admin1CodesASCII.txt...\n",
      "Loaded 3893 Admin1 name mappings.\n",
      "Loading Admin2 names from natural_earth_data/admin2Codes.txt...\n",
      "Loaded 47356 Admin2 name mappings.\n",
      "\n",
      "--- Mapping Admin Codes to Names ---\n",
      "Admin1 names mapped.\n",
      "Admin2 names mapped.\n",
      "Converting GeoNames data to GeoDataFrame...\n",
      "Building KDTree for GeoNames cities...\n",
      "KDTree built successfully.\n",
      "215735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>[Casas Vila, Vila]</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>[surudeu, سولدو, スルデウ, swldw, סולדאו, Sol'deu,...</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>[Sispony]</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>[Ehl Tarter, Эл Тартер, Ел Тартер, ال تارتر, E...</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>[sheng hu li ya-de luo li ya, Sant-Zhulija-de-...</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city_name  city_latitude  city_longitude city_country_code  \\\n",
       "0                 Vila       42.53176         1.56654                AD   \n",
       "1               Soldeu       42.57688         1.66769                AD   \n",
       "2              Sispony       42.53368         1.51613                AD   \n",
       "3            El Tarter       42.57952         1.65362                AD   \n",
       "4  Sant Julià de Lòria       42.46372         1.49129                AD   \n",
       "\n",
       "   city_population                                     alternatenames  \\\n",
       "0             1418                                 [Casas Vila, Vila]   \n",
       "1              602  [surudeu, سولدو, スルデウ, swldw, סולדאו, Sol'deu,...   \n",
       "2              833                                          [Sispony]   \n",
       "3             1052  [Ehl Tarter, Эл Тартер, Ел Тартер, ال تارتر, E...   \n",
       "4             8022  [sheng hu li ya-de luo li ya, Sant-Zhulija-de-...   \n",
       "\n",
       "      city_admin1_name city_admin2_name                  geometry    source  \n",
       "0               Encamp                   POINT (1.56654 42.53176)  geonames  \n",
       "1              Canillo                   POINT (1.66769 42.57688)  geonames  \n",
       "2           La Massana                   POINT (1.51613 42.53368)  geonames  \n",
       "3              Canillo                   POINT (1.65362 42.57952)  geonames  \n",
       "4  Sant Julià de Loria                   POINT (1.49129 42.46372)  geonames  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_city_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the city_name and alternatenames columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with 'city_name' and 'alternatenames' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()    \n",
    "\n",
    "    # 1. Fill any NaN values in 'alternatenames' with an empty string.\n",
    "    # 2. Apply a lambda function to split the string by commas.\n",
    "    # 3. Inside the lambda, use a list comprehension to strip whitespace from each resulting string.\n",
    "    # 4. This ensures every entry in the 'alternatenames' column is a list of clean strings.\n",
    "    df['alternatenames'] = df['alternatenames'].fillna('').apply(\n",
    "        lambda x: [s.strip() for s in x.split(',') if s.strip()]\n",
    "    )\n",
    "\n",
    "    # Function to process each city name\n",
    "    def process_city_name(row):\n",
    "        # Use str() as a safeguard against potential non-string city names\n",
    "        city_name = str(row['city_name'])\n",
    "\n",
    "        alternatenames = list(row['alternatenames'])  # It's a list, so proceed\n",
    "\n",
    "        # Always append the original city name to alternatenames\n",
    "        # This preserves the original data before any modifications.\n",
    "        if city_name:\n",
    "             alternatenames.append(city_name.strip())\n",
    "\n",
    "        # If country is PH, remove all traces of \"Brgy.\" ---\n",
    "        if row['city_country_code'] == 'PH':\n",
    "            city_name = re.sub(r'Brgy\\.\\s*', '', city_name, flags=re.IGNORECASE).strip()\n",
    "\n",
    "        # Extract content from square brackets\n",
    "        bracketed_content = re.findall(r'\\[(.*?)\\]', city_name)\n",
    "        if bracketed_content:\n",
    "            for content in bracketed_content:\n",
    "                alternatenames.extend([name.strip() for name in content.split(',')])\n",
    "            city_name = re.sub(r'\\s*\\[.*?\\]\\s*', '', city_name).strip()\n",
    "\n",
    "        # Extract content from parentheses\n",
    "        parenthetical_content = re.findall(r'\\((.*?)\\)', city_name)\n",
    "        if parenthetical_content:\n",
    "            for content in parenthetical_content:\n",
    "                alternatenames.extend([name.strip() for name in content.split(',')])\n",
    "            city_name = re.sub(r'\\s*\\(.*?\\)\\s*', '', city_name).strip()\n",
    "\n",
    "        # Split by slash and update city_name and alternatenames\n",
    "        if '/' in city_name:\n",
    "            parts = [part.strip() for part in city_name.split('/')]\n",
    "            city_name = parts[-1]\n",
    "            alternatenames.extend(parts[:-1])\n",
    "\n",
    "        # Process commas\n",
    "        if ',' in city_name:\n",
    "            parts = [part.strip() for part in city_name.split(',')]\n",
    "            city_name = parts[0]\n",
    "            alternatenames.extend(parts[1:])\n",
    "\n",
    "        # Clean up lists and remove duplicates\n",
    "        row['city_name'] = city_name.strip()\n",
    "        # Filter out any potential empty strings that may have been created during the process\n",
    "        row['alternatenames'] = list(set(alt for alt in alternatenames if alt))\n",
    "        return row\n",
    "\n",
    "    # Apply the function to each row of the DataFrame\n",
    "    df = df.apply(process_city_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df, _ = data_loader.load_cities_and_build_kdtree_from_geonames()\n",
    "df = clean_city_data(df) \n",
    "df[\"source\"] = \"geonames\"\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b286de7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [city_name, city_latitude, city_longitude, city_country_code, city_population, alternatenames, city_admin1_name, city_admin2_name, geometry, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"city_name\"].str.contains(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e684630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>alternatenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47589</th>\n",
       "      <td>Tchitado</td>\n",
       "      <td>Tchitado</td>\n",
       "      <td>-17.3167</td>\n",
       "      <td>13.9167</td>\n",
       "      <td>Angola</td>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Cunene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1024158837</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Tchitado]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>Yakossi</td>\n",
       "      <td>Yakossi</td>\n",
       "      <td>5.6170</td>\n",
       "      <td>23.3167</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>CF</td>\n",
       "      <td>CAF</td>\n",
       "      <td>Mbomou</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1140246753</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Yakossi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47591</th>\n",
       "      <td>Tmassah</td>\n",
       "      <td>Tmassah</td>\n",
       "      <td>26.3667</td>\n",
       "      <td>15.8000</td>\n",
       "      <td>Libya</td>\n",
       "      <td>LY</td>\n",
       "      <td>LBY</td>\n",
       "      <td>Murzuq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1434333715</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Tmassah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47592</th>\n",
       "      <td>Puerto Pinasco</td>\n",
       "      <td>Puerto Pinasco</td>\n",
       "      <td>-22.6400</td>\n",
       "      <td>-57.7900</td>\n",
       "      <td>Paraguay</td>\n",
       "      <td>PY</td>\n",
       "      <td>PRY</td>\n",
       "      <td>Presidente Hayes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1600670025</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Puerto Pinasco]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47593</th>\n",
       "      <td>Oymyakon</td>\n",
       "      <td>Oymyakon</td>\n",
       "      <td>63.4608</td>\n",
       "      <td>142.7858</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Sakha (Yakutiya)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1643797797</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Oymyakon]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city      city_ascii      lat       lng  \\\n",
       "47589        Tchitado        Tchitado -17.3167   13.9167   \n",
       "47590         Yakossi         Yakossi   5.6170   23.3167   \n",
       "47591         Tmassah         Tmassah  26.3667   15.8000   \n",
       "47592  Puerto Pinasco  Puerto Pinasco -22.6400  -57.7900   \n",
       "47593        Oymyakon        Oymyakon  63.4608  142.7858   \n",
       "\n",
       "                        country iso2 iso3        admin_name capital  \\\n",
       "47589                    Angola   AO  AGO            Cunene     NaN   \n",
       "47590  Central African Republic   CF  CAF            Mbomou     NaN   \n",
       "47591                     Libya   LY  LBY            Murzuq     NaN   \n",
       "47592                  Paraguay   PY  PRY  Presidente Hayes     NaN   \n",
       "47593                    Russia   RU  RUS  Sakha (Yakutiya)     NaN   \n",
       "\n",
       "       population          id       source    alternatenames  \n",
       "47589       500.0  1024158837  worldcities        [Tchitado]  \n",
       "47590       500.0  1140246753  worldcities         [Yakossi]  \n",
       "47591       500.0  1434333715  worldcities         [Tmassah]  \n",
       "47592       500.0  1600670025  worldcities  [Puerto Pinasco]  \n",
       "47593       500.0  1643797797  worldcities        [Oymyakon]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_city_data2(df):\n",
    "    \"\"\"\n",
    "    Cleans the city_name and alternatenames columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with 'city_name' and 'alternatenames' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()    \n",
    "\n",
    "    def create_list_column(row, col1, col2):\n",
    "        \"\"\"\n",
    "        Creates a list from two columns, excluding null values.\n",
    "\n",
    "        Args:\n",
    "            row: A row of the DataFrame.\n",
    "            col1: The name of the first column.\n",
    "            col2: The name of the second column.\n",
    "\n",
    "        Returns:\n",
    "            A list containing non-null values from col1 and col2.\n",
    "        \"\"\"\n",
    "        values = []\n",
    "\n",
    "        # **CRITICAL**: Only add the name if it's a non-empty string.\n",
    "        # This prevents NaN (float) values from being added to the set.\n",
    "        if isinstance(row[col1], str) and row[col1]:\n",
    "            values.append(row[col1])\n",
    "        if isinstance(row[col2], str) and row[col2]:\n",
    "            values.append(row[col2])\n",
    "        return values\n",
    "\n",
    "    df['alternatenames'] = df.apply(lambda row: create_list_column(row, 'city', 'city_ascii'), axis=1)\n",
    "\n",
    "\n",
    "    # Function to process each city name\n",
    "    def process_city_name(row):\n",
    "        # Use str() as a safeguard against potential non-string city names\n",
    "        city_name = str(row['city_ascii'])\n",
    "\n",
    "        alternatenames = list(row['alternatenames'])  # It's a list, so proceed\n",
    "\n",
    "        # Always append the original city name to alternatenames\n",
    "        # This preserves the original data before any modifications.\n",
    "        if city_name:\n",
    "             alternatenames.append(city_name.strip())\n",
    "\n",
    "        # If country is PH, remove all traces of \"Brgy.\" ---\n",
    "        if row['iso2'] == 'PH':\n",
    "            city_name = re.sub(r'Brgy\\.\\s*', '', city_name, flags=re.IGNORECASE).strip()\n",
    "\n",
    "        # Extract content from square brackets\n",
    "        bracketed_content = re.findall(r'\\[(.*?)\\]', city_name)\n",
    "        if bracketed_content:\n",
    "            for content in bracketed_content:\n",
    "                alternatenames.extend([name.strip() for name in content.split(',')])\n",
    "            city_name = re.sub(r'\\s*\\[.*?\\]\\s*', '', city_name).strip()\n",
    "\n",
    "        # Extract content from parentheses\n",
    "        parenthetical_content = re.findall(r'\\((.*?)\\)', city_name)\n",
    "        if parenthetical_content:\n",
    "            for content in parenthetical_content:\n",
    "                alternatenames.extend([name.strip() for name in content.split(',')])\n",
    "            city_name = re.sub(r'\\s*\\(.*?\\)\\s*', '', city_name).strip()\n",
    "\n",
    "        # Split by slash and update city_name and alternatenames\n",
    "        if '/' in city_name:\n",
    "            parts = [part.strip() for part in city_name.split('/')]\n",
    "            city_name = parts[-1]\n",
    "            alternatenames.extend(parts[:-1])\n",
    "\n",
    "        # Process commas\n",
    "        if ',' in city_name:\n",
    "            parts = [part.strip() for part in city_name.split(',')]\n",
    "            city_name = parts[0]\n",
    "            alternatenames.extend(parts[1:])\n",
    "\n",
    "        # Clean up lists and remove duplicates\n",
    "        row['city_ascii'] = city_name.strip()\n",
    "        row[\"city\"] = row[\"city\"].strip()\n",
    "        # Filter out any potential empty strings that may have been created during the process\n",
    "        row['alternatenames'] = list(set(alt for alt in alternatenames if alt))\n",
    "        return row\n",
    "\n",
    "    # Apply the function to each row of the DataFrame\n",
    "    df = df.apply(process_city_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('natural_earth_data/worldcities.csv')\n",
    "if not include_all_worldcities:\n",
    "    df2 = df2[df2[\"population\"] <= 500]\n",
    "df2['population'] = df2['population'].fillna(0)\n",
    "nyc_filter = (df2['city'] == 'New York') & (df2['admin_name'] == 'New York')\n",
    "df2.loc[nyc_filter, ['city', 'city_ascii']] = 'New York City'\n",
    "print(len(df2))\n",
    "df2[\"source\"] = \"worldcities\"\n",
    "df2 = clean_city_data2(df2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff14476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>alternatenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47803</th>\n",
       "      <td>Kostel</td>\n",
       "      <td>Kostel</td>\n",
       "      <td>45.5088</td>\n",
       "      <td>14.9100</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>SI</td>\n",
       "      <td>SVN</td>\n",
       "      <td>Kostel</td>\n",
       "      <td>admin</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1705541759</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Kostel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47804</th>\n",
       "      <td>Kingoonya</td>\n",
       "      <td>Kingoonya</td>\n",
       "      <td>-30.9170</td>\n",
       "      <td>135.3147</td>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1036942792</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Kingoonya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47826</th>\n",
       "      <td>Chuquicamata</td>\n",
       "      <td>Chuquicamata</td>\n",
       "      <td>-22.3169</td>\n",
       "      <td>-68.9301</td>\n",
       "      <td>Chile</td>\n",
       "      <td>CL</td>\n",
       "      <td>CHL</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1152468996</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Chuquicamata]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47969</th>\n",
       "      <td>Nordvik</td>\n",
       "      <td>Nordvik</td>\n",
       "      <td>73.9975</td>\n",
       "      <td>111.4633</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Krasnoyarskiy Kray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643587468</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Nordvik]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47970</th>\n",
       "      <td>Logashkino</td>\n",
       "      <td>Logashkino</td>\n",
       "      <td>70.8500</td>\n",
       "      <td>153.9167</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Sakha (Yakutiya)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643050775</td>\n",
       "      <td>worldcities</td>\n",
       "      <td>[Logashkino]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city    city_ascii      lat       lng    country iso2 iso3  \\\n",
       "47803        Kostel        Kostel  45.5088   14.9100   Slovenia   SI  SVN   \n",
       "47804     Kingoonya     Kingoonya -30.9170  135.3147  Australia   AU  AUS   \n",
       "47826  Chuquicamata  Chuquicamata -22.3169  -68.9301      Chile   CL  CHL   \n",
       "47969       Nordvik       Nordvik  73.9975  111.4633     Russia   RU  RUS   \n",
       "47970    Logashkino    Logashkino  70.8500  153.9167     Russia   RU  RUS   \n",
       "\n",
       "               admin_name capital  population          id       source  \\\n",
       "47803              Kostel   admin        10.0  1705541759  worldcities   \n",
       "47804     South Australia     NaN         4.0  1036942792  worldcities   \n",
       "47826         Antofagasta     NaN         0.0  1152468996  worldcities   \n",
       "47969  Krasnoyarskiy Kray     NaN         0.0  1643587468  worldcities   \n",
       "47970    Sakha (Yakutiya)     NaN         0.0  1643050775  worldcities   \n",
       "\n",
       "       alternatenames  \n",
       "47803        [Kostel]  \n",
       "47804     [Kingoonya]  \n",
       "47826  [Chuquicamata]  \n",
       "47969       [Nordvik]  \n",
       "47970    [Logashkino]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4ee645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Intelligent Merge Process ---\n",
      "Step A: Creating a lookup map from geonames names and aliases...\n",
      "  Created a map with 853439 unique name aliases.\n",
      "Step B: Matching worldcities against geonames map...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Processing worldcities: 100%|██████████| 219/219 [00:00<00:00, 12115.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step C: Preparing and appending new cities from worldcities...\n",
      "  Found 145 new cities to append.\n",
      "\n",
      "--- Intelligent Merge Complete! 215880 entries---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>source</th>\n",
       "      <th>worldcities_admin1_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48e8d39f793285b5</td>\n",
       "      <td>Vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>[Casas Vila, Vila]</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "      <td>geonames</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5f18e80ec393424</td>\n",
       "      <td>Soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>[surudeu, سولدو, スルデウ, swldw, סולדאו, Sol'deu,...</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "      <td>geonames</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38132557d06759a4</td>\n",
       "      <td>Sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>[Sispony]</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "      <td>geonames</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6223f9846326a714</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>[Ehl Tarter, Эл Тартер, Ел Тартер, ال تارتر, E...</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "      <td>geonames</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8c4de62071e99deb</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>[sheng hu li ya-de luo li ya, Sant-Zhulija-de-...</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "      <td>geonames</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city_id            city_name  city_latitude  city_longitude  \\\n",
       "0  48e8d39f793285b5                 Vila       42.53176         1.56654   \n",
       "1  a5f18e80ec393424               Soldeu       42.57688         1.66769   \n",
       "2  38132557d06759a4              Sispony       42.53368         1.51613   \n",
       "3  6223f9846326a714            El Tarter       42.57952         1.65362   \n",
       "4  8c4de62071e99deb  Sant Julià de Lòria       42.46372         1.49129   \n",
       "\n",
       "  city_country_code  city_population  \\\n",
       "0                AD             1418   \n",
       "1                AD              602   \n",
       "2                AD              833   \n",
       "3                AD             1052   \n",
       "4                AD             8022   \n",
       "\n",
       "                                      alternatenames     city_admin1_name  \\\n",
       "0                                 [Casas Vila, Vila]               Encamp   \n",
       "1  [surudeu, سولدو, スルデウ, swldw, סולדאו, Sol'deu,...              Canillo   \n",
       "2                                          [Sispony]           La Massana   \n",
       "3  [Ehl Tarter, Эл Тартер, Ел Тартер, ال تارتر, E...              Canillo   \n",
       "4  [sheng hu li ya-de luo li ya, Sant-Zhulija-de-...  Sant Julià de Loria   \n",
       "\n",
       "  city_admin2_name                  geometry    source worldcities_admin1_name  \n",
       "0                   POINT (1.56654 42.53176)  geonames                    None  \n",
       "1                   POINT (1.66769 42.57688)  geonames                    None  \n",
       "2                   POINT (1.51613 42.53368)  geonames                    None  \n",
       "3                   POINT (1.65362 42.57952)  geonames                    None  \n",
       "4                   POINT (1.49129 42.46372)  geonames                    None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation and lowercases it.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text.lower())\n",
    "    return text\n",
    "\n",
    "def merge_geonames_with_worldcities(gdf_geonames, df_worldcities):\n",
    "    \"\"\"\n",
    "    Intelligently merges worldcities data into a geonames GeoDataFrame,\n",
    "    capturing alternate admin names and assigning a unique city_id.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Intelligent Merge Process ---\")\n",
    "    \n",
    "    # Add a column to store potential alternate admin names from worldcities\n",
    "    gdf_geonames['worldcities_admin1_name'] = None\n",
    "\n",
    "    # --- Part A: Create a fast lookup map from all geonames aliases ---\n",
    "    print(\"Step A: Creating a lookup map from geonames names and aliases...\")\n",
    "    # ... (rest of Part A is unchanged) ...\n",
    "    name_to_geonames_index = {}\n",
    "    for idx, row in gdf_geonames.iterrows():\n",
    "        country_code = row['city_country_code']\n",
    "        admin_1_code = normalize_text(row['city_admin1_name'])\n",
    "        main_name_norm = normalize_text(row['city_name'])\n",
    "        if main_name_norm:\n",
    "            name_to_geonames_index[(main_name_norm, admin_1_code, country_code)] = idx\n",
    "        for alt_name in row['alternatenames']:\n",
    "            alt_name_norm = normalize_text(alt_name)\n",
    "            if alt_name_norm:\n",
    "                name_to_geonames_index[(alt_name_norm, admin_1_code, country_code)] = idx\n",
    "    print(f\"  Created a map with {len(name_to_geonames_index)} unique name aliases.\")\n",
    "\n",
    "    # --- Part B: Iterate through worldcities and merge/append ---\n",
    "    print(\"Step B: Matching worldcities against geonames map...\")\n",
    "    df_worldcities_processed = df_worldcities.copy()\n",
    "    df_worldcities_processed['merged_into_geonames'] = False\n",
    "\n",
    "    for idx, row in tqdm(df_worldcities_processed.iterrows(), total=df_worldcities_processed.shape[0], desc=\"  Processing worldcities\"):\n",
    "        country_code = row['iso2'] \n",
    "        admin_1_code = normalize_text(row['admin_name'])\n",
    "        city_norm = normalize_text(row['city'])\n",
    "        city_ascii_norm = normalize_text(row['city_ascii'])\n",
    "        geonames_match_idx = name_to_geonames_index.get((city_norm, admin_1_code, country_code)) or name_to_geonames_index.get((city_ascii_norm, admin_1_code, country_code))\n",
    "\n",
    "        if geonames_match_idx is not None:\n",
    "            # Match found! Update alternatenames\n",
    "            existing_alternames = gdf_geonames.at[geonames_match_idx, 'alternatenames']\n",
    "            updated_alternames = set(existing_alternames)\n",
    "            updated_alternames.update(row[\"alternatenames\"])\n",
    "            gdf_geonames.at[geonames_match_idx, 'alternatenames'] = sorted(list(updated_alternames))\n",
    "            \n",
    "            # *** NEW: Capture the admin name from worldcities as a potential alternate ***\n",
    "            gdf_geonames.at[geonames_match_idx, 'worldcities_admin1_name'] = row['admin_name']\n",
    "\n",
    "            df_worldcities_processed.at[idx, 'merged_into_geonames'] = True\n",
    "\n",
    "    # --- Part C: Prepare and concatenate the non-merged cities ---\n",
    "    print(\"Step C: Preparing and appending new cities from worldcities...\")\n",
    "    # ... (rest of Part C is mostly unchanged) ...\n",
    "    new_cities = df_worldcities_processed[~df_worldcities_processed['merged_into_geonames']].copy()\n",
    "    print(f\"  Found {len(new_cities)} new cities to append.\")\n",
    "\n",
    "    if not new_cities.empty:\n",
    "        new_cities.rename(columns={\n",
    "            'city': 'city_name', 'lat': 'city_latitude', 'lng': 'city_longitude',\n",
    "            'iso2': 'city_country_code', 'population': 'city_population',\n",
    "            'admin_name': 'city_admin1_name'\n",
    "        }, inplace=True)\n",
    "        # For new cities, the worldcities admin name is just its own admin name\n",
    "        new_cities['worldcities_admin1_name'] = new_cities['city_admin1_name']\n",
    "        new_cities['city_admin2_name'] = \"\"\n",
    "        new_cities['geometry'] = gpd.points_from_xy(new_cities['city_longitude'], new_cities['city_latitude'])\n",
    "        \n",
    "        final_columns = [col for col in gdf_geonames.columns if col in new_cities.columns]\n",
    "        new_cities_gdf = gpd.GeoDataFrame(new_cities[final_columns], crs=\"EPSG:4326\")\n",
    "        \n",
    "        gdf_merged = pd.concat([gdf_geonames, new_cities_gdf], ignore_index=True)\n",
    "    else:\n",
    "        gdf_merged = gdf_geonames.copy()\n",
    "\n",
    "    # --- Part D: Finalize with unique ID and clean data types ---\n",
    "    def create_hashed_id(row, cols_to_hash, length=16):\n",
    "        \"\"\"\n",
    "        Creates a truncated SHA-256 hash from specified columns of a DataFrame row.\n",
    "        \"\"\"\n",
    "        # Concatenate values with a separator for stability\n",
    "        string_to_hash = ''.join([str(row[col]) for col in cols_to_hash])\n",
    "        \n",
    "        # Encode the string to bytes, required for hashlib\n",
    "        encoded_string = string_to_hash.encode('utf-8')\n",
    "        \n",
    "        # Create the hash and return the first `length` characters of the hex digest\n",
    "        sha256_hash = hashlib.sha256(encoded_string).hexdigest()\n",
    "        \n",
    "        return sha256_hash[:length]\n",
    "    gdf_merged.insert(0, 'city_id', gdf_merged.index)\n",
    "    gdf_merged[\"city_id\"] = gdf_merged.apply(\n",
    "        create_hashed_id, \n",
    "        cols_to_hash=[\"city_name\", \"city_latitude\", \"city_longitude\", \"city_country_code\", \"city_population\", \"city_admin1_name\", \"worldcities_admin1_name\"], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    gdf_merged['city_population'] = pd.to_numeric(gdf_merged['city_population'], errors='coerce').astype(pd.Int64Dtype())\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Intelligent Merge Complete! {len(gdf_merged)} entries---\")\n",
    "    return gdf_merged\n",
    "\n",
    "merged_gdf = merge_geonames_with_worldcities(df, df2)\n",
    "merged_gdf = merged_gdf.drop_duplicates(subset=['city_id'], keep=\"first\")\n",
    "\n",
    "merged_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ccfa38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215880\n",
      "215880\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_gdf))\n",
    "print(len(set(merged_gdf[\"city_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0403e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Three-Tier HDBSCAN Clustering Process ---\n",
      "Step 1: Preparing combined data for clustering...\n",
      "  Processing 215880 total cities.\n",
      "\n",
      "Step 2: Running HDBSCAN clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HDBSCAN found 5756 clusters.\n",
      "\n",
      "Step 3: Identifying representatives for all three metro tiers...\n",
      "\n",
      "Step 4: Merging three-tier results back into the DataFrame...\n",
      "\n",
      "--- Process Complete! ---\n",
      "Final DataFrame has 215880 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_name_normalized</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>greater_metro_name</th>\n",
       "      <th>greater_metro_id</th>\n",
       "      <th>greater_metro_in_country_name</th>\n",
       "      <th>greater_metro_in_country_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48e8d39f793285b5</td>\n",
       "      <td>Vila</td>\n",
       "      <td>vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>[Casas Vila, Vila, vila]</td>\n",
       "      <td>encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "      <td>encamp</td>\n",
       "      <td>6176dbe2fec29734</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5f18e80ec393424</td>\n",
       "      <td>Soldeu</td>\n",
       "      <td>soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>[Sol'deu, Soldeu, soldeu, surudeu, swldw, Соль...</td>\n",
       "      <td>canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "      <td>canillo</td>\n",
       "      <td>f92dba31f62d7810</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38132557d06759a4</td>\n",
       "      <td>Sispony</td>\n",
       "      <td>sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>[Sispony, sispony]</td>\n",
       "      <td>la massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "      <td>la massana</td>\n",
       "      <td>8334e238d8413912</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6223f9846326a714</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>el tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>[Ehl Tarter, El Tarter, El Tarter - Principau ...</td>\n",
       "      <td>canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "      <td>canillo</td>\n",
       "      <td>f92dba31f62d7810</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8c4de62071e99deb</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>sant julia de loria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>[San Julia, San Julià, Sant Julia de Loria, Sa...</td>\n",
       "      <td>sant julia de loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "      <td>sant julia de loria</td>\n",
       "      <td>8c4de62071e99deb</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city_id            city_name city_name_normalized  city_latitude  \\\n",
       "0  48e8d39f793285b5                 Vila                 vila       42.53176   \n",
       "1  a5f18e80ec393424               Soldeu               soldeu       42.57688   \n",
       "2  38132557d06759a4              Sispony              sispony       42.53368   \n",
       "3  6223f9846326a714            El Tarter            el tarter       42.57952   \n",
       "4  8c4de62071e99deb  Sant Julià de Lòria  sant julia de loria       42.46372   \n",
       "\n",
       "   city_longitude city_country_code  city_population  \\\n",
       "0         1.56654                AD             1418   \n",
       "1         1.66769                AD              602   \n",
       "2         1.51613                AD              833   \n",
       "3         1.65362                AD             1052   \n",
       "4         1.49129                AD             8022   \n",
       "\n",
       "                                      alternatenames     city_admin1_name  \\\n",
       "0                           [Casas Vila, Vila, vila]               encamp   \n",
       "1  [Sol'deu, Soldeu, soldeu, surudeu, swldw, Соль...              canillo   \n",
       "2                                 [Sispony, sispony]           la massana   \n",
       "3  [Ehl Tarter, El Tarter, El Tarter - Principau ...              canillo   \n",
       "4  [San Julia, San Julià, Sant Julia de Loria, Sa...  sant julia de loria   \n",
       "\n",
       "  city_admin2_name                  geometry           metro_name  \\\n",
       "0                   POINT (1.56654 42.53176)               encamp   \n",
       "1                   POINT (1.66769 42.57688)              canillo   \n",
       "2                   POINT (1.51613 42.53368)           la massana   \n",
       "3                   POINT (1.65362 42.57952)              canillo   \n",
       "4                   POINT (1.49129 42.46372)  sant julia de loria   \n",
       "\n",
       "           metro_id greater_metro_name  greater_metro_id  \\\n",
       "0  6176dbe2fec29734   andorra la vella  e098c520e9b6b97a   \n",
       "1  f92dba31f62d7810   andorra la vella  e098c520e9b6b97a   \n",
       "2  8334e238d8413912   andorra la vella  e098c520e9b6b97a   \n",
       "3  f92dba31f62d7810   andorra la vella  e098c520e9b6b97a   \n",
       "4  8c4de62071e99deb   andorra la vella  e098c520e9b6b97a   \n",
       "\n",
       "  greater_metro_in_country_name greater_metro_in_country_id    source  \n",
       "0              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "1              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "2              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "3              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "4              andorra la vella            e098c520e9b6b97a  geonames  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hdbscan\n",
    "import numpy as np\n",
    "\n",
    "def cluster_cities_with_hdbscan_three_tier_simplified(\n",
    "    gdf_all_cities,\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None,\n",
    "    cluster_selection_epsilon_meters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies a three-tiered metropolitan hierarchy using HDBSCAN on a pre-merged dataset.\n",
    "    This version uses a persistent `city_id` for all associations.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Three-Tier HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare Data ---\n",
    "    print(\"Step 1: Preparing combined data for clustering...\")\n",
    "    gdf_proc = gdf_all_cities.copy()\n",
    "    \n",
    "    # Normalize admin names and fill NaNs\n",
    "    for col in ['city_admin1_name', 'city_admin2_name']:\n",
    "        gdf_proc[col] = gdf_proc[col].apply(normalize_text).fillna('')\n",
    "    print(f\"  Processing {len(gdf_proc)} total cities.\")\n",
    "    \n",
    "    # --- Step 2: Project Data and Run HDBSCAN ---\n",
    "    print(\"\\nStep 2: Running HDBSCAN clustering...\")\n",
    "    gdf_proj = gdf_proc.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_proj.geometry.x, gdf_proj.geometry.y)))\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon_meters or 0\n",
    "    )\n",
    "    clusterer.fit(coords)\n",
    "    gdf_proc['cluster_id'] = clusterer.labels_\n",
    "    print(f\"  HDBSCAN found {len(np.unique(clusterer.labels_)) - 1} clusters.\")\n",
    "\n",
    "    # --- Step 3: Identify Representatives for All Three Tiers ---\n",
    "    print(\"\\nStep 3: Identifying representatives for all three metro tiers...\")\n",
    "    clustered_cities = gdf_proc[gdf_proc['cluster_id'] != -1]\n",
    "\n",
    "    # Find the index of the most populous city for each tier\n",
    "    idx_greater = clustered_cities.groupby('cluster_id')['city_population'].idxmax()\n",
    "    idx_greater_country = clustered_cities.groupby(['cluster_id', 'city_country_code'])['city_population'].idxmax()\n",
    "    idx_local = clustered_cities.groupby(['cluster_id', 'city_country_code', 'city_admin1_name', 'city_admin2_name'])['city_population'].idxmax()\n",
    "\n",
    "    # Create mapping tables using the city_id of the representative cities\n",
    "    greater_map = gdf_proc.loc[idx_greater, ['cluster_id', 'city_name', 'city_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_name', 'city_id': 'greater_metro_id'}\n",
    "    )\n",
    "    greater_country_map = gdf_proc.loc[idx_greater_country, ['cluster_id', 'city_country_code', 'city_name', 'city_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_in_country_name', 'city_id': 'greater_metro_in_country_id'}\n",
    "    )\n",
    "    local_map = gdf_proc.loc[idx_local, ['cluster_id', 'city_country_code', 'city_admin1_name', 'city_admin2_name', 'city_name', 'city_id']].rename(\n",
    "        columns={'city_name': 'metro_name', 'city_id': 'metro_id'}\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Map All Tiers Back to the Main DataFrame ---\n",
    "    print(\"\\nStep 4: Merging three-tier results back into the DataFrame...\")\n",
    "    gdf_merged = gdf_proc.merge(greater_map, on='cluster_id', how='left')\n",
    "    gdf_merged = gdf_merged.merge(greater_country_map, on=['cluster_id', 'city_country_code'], how='left')\n",
    "    gdf_merged = gdf_merged.merge(local_map, on=['cluster_id', 'city_country_code', 'city_admin1_name', 'city_admin2_name'], how='left')\n",
    "\n",
    "    # For any city not in a cluster, it is its own metro representative\n",
    "    for tier_prefix in ['metro', 'greater_metro_in_country', 'greater_metro']:\n",
    "        is_unmatched = gdf_merged[f'{tier_prefix}_name'].isna()\n",
    "        gdf_merged.loc[is_unmatched, f'{tier_prefix}_name'] = gdf_merged.loc[is_unmatched, 'city_name']\n",
    "        gdf_merged.loc[is_unmatched, f'{tier_prefix}_id'] = gdf_merged.loc[is_unmatched, 'city_id']\n",
    "\n",
    "    # --- Step 5: Final Cleanup ---\n",
    "    # Normalize metro names and ensure ID columns are integer\n",
    "    for col in [\"greater_metro_name\", \"greater_metro_in_country_name\", \"metro_name\"]:\n",
    "        gdf_merged[col] = gdf_merged[col].apply(normalize_text).fillna('')\n",
    "    for col in [\"greater_metro_id\", \"greater_metro_in_country_id\", \"metro_id\"]:\n",
    "        gdf_merged[col] = gdf_merged[col].astype(str)\n",
    "\n",
    "    # Add normalized city name and ensure alternames are unique\n",
    "    gdf_merged.insert(loc=2, column='city_name_normalized', value=gdf_merged[\"city_name\"].apply(normalize_text))\n",
    "    def create_list_column(row, col1, col2):\n",
    "        \"\"\"\n",
    "        Creates a list from two columns, excluding null values.\n",
    "\n",
    "        Args:\n",
    "            row: A row of the DataFrame.\n",
    "            col1: The name of the first column.\n",
    "            col2: The name of the second column.\n",
    "\n",
    "        Returns:\n",
    "            A list containing non-null values from col1 and col2.\n",
    "        \"\"\"\n",
    "        values = row[\"alternatenames\"]\n",
    "\n",
    "        # **CRITICAL**: Only add the name if it's a non-empty string.\n",
    "        # This prevents NaN (float) values from being added to the set.\n",
    "        if isinstance(row[col1], str) and row[col1]:\n",
    "            values.append(row[col1])\n",
    "        if isinstance(row[col2], str) and row[col2]:\n",
    "            values.append(row[col2])\n",
    "        \n",
    "        return list(set(values))\n",
    "\n",
    "    gdf_merged['alternatenames'] = gdf_merged.apply(lambda row: create_list_column(row, 'city_name', 'city_name_normalized'), axis=1)\n",
    "    gdf_merged['alternatenames'] = gdf_merged['alternatenames'].apply(lambda x: sorted(list(set(x))))\n",
    "    \n",
    "    # Define and order final columns\n",
    "    final_cols = [\n",
    "        'city_id', 'city_name', 'city_name_normalized', 'city_latitude', 'city_longitude',\n",
    "        'city_country_code', 'city_population', 'alternatenames', 'city_admin1_name',\n",
    "        'city_admin2_name', 'geometry', 'metro_name',\n",
    "        'metro_id', 'greater_metro_name', 'greater_metro_id',\n",
    "        'greater_metro_in_country_name', 'greater_metro_in_country_id',  'source'\n",
    "    ]\n",
    "    gdf_final = gdf_merged[final_cols]\n",
    "    \n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    return gdf_final\n",
    "\n",
    "final_gdf_tuned = cluster_cities_with_hdbscan_three_tier_simplified(merged_gdf)\n",
    "\n",
    "print(f\"Final DataFrame has {len(final_gdf_tuned)} entries.\")\n",
    "final_gdf_tuned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d361bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_admin_mappings(gdf_in):\n",
    "    \"\"\"\n",
    "    Creates mapping tables for admin1 and admin2 names with unique IDs, \n",
    "    alternate names, and country context. This version uses normalized names\n",
    "    and country codes for reliable joining and uniqueness.\n",
    "    \n",
    "    Args:\n",
    "        gdf_in (gpd.GeoDataFrame): The input GeoDataFrame which must contain:\n",
    "            'city_admin1_name', 'city_admin2_name', 'city_country_code',\n",
    "            'city_population', and 'worldcities_admin1_name'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two pandas DataFrames:\n",
    "               (admin1_map_df, admin2_map_df).\n",
    "    \"\"\"\n",
    "    print(\"--- Creating Admin Name Mapping Tables ---\")\n",
    "    gdf = gdf_in.copy()\n",
    "    \n",
    "    # Pre-calculate normalized names to be used as keys for grouping\n",
    "    gdf['city_admin1_name_normalized'] = gdf['city_admin1_name'].apply(normalize_text)\n",
    "    gdf['city_admin2_name_normalized'] = gdf['city_admin2_name'].apply(normalize_text)\n",
    "\n",
    "    # --- Admin1 Mapping ---\n",
    "    print(\"Processing Admin1 names...\")\n",
    "    admin1_data = []\n",
    "    \n",
    "    # Filter for valid admin1 entries and group by normalized name and country code\n",
    "    admin1_gdf = gdf[gdf['city_admin1_name_normalized'].notna() & (gdf['city_admin1_name_normalized'] != '')].copy()\n",
    "    grouped_admin1 = admin1_gdf.groupby(['city_admin1_name_normalized', 'city_country_code'])\n",
    "    \n",
    "    for (name_norm, country_code), group in grouped_admin1:\n",
    "        # Choose the display name from the most populous city within the group\n",
    "        rep_row = group.loc[group['city_population'].fillna(0).idxmax()]\n",
    "        display_name = rep_row['city_admin1_name']\n",
    "        \n",
    "        # Collect all possible alternate names from the group\n",
    "        alt_names = set()\n",
    "        # Add all original admin1 names (e.g., \"Tōkyō\")\n",
    "        alt_names.update(n for n in group['city_admin1_name'].dropna() if n.strip())\n",
    "        # Add all worldcities admin1 names (e.g., \"Tokyo\")\n",
    "        alt_names.update(n for n in group['worldcities_admin1_name'].dropna() if n.strip())\n",
    "        \n",
    "        # Add normalized versions of all collected names (e.g., \"tokyo\")\n",
    "        normalized_alts = {normalize_text(name) for name in alt_names}\n",
    "        alt_names.update(normalized_alts)\n",
    "        \n",
    "        admin1_data.append({\n",
    "            'admin1_name_normalized': name_norm,\n",
    "            'country_code': country_code,\n",
    "            'admin1_name': display_name,\n",
    "            'admin1_alternatenames': sorted(list(alt_names))\n",
    "        })\n",
    "\n",
    "    admin1_map_df = pd.DataFrame(admin1_data)\n",
    "    # Sort for a stable index before assigning the ID\n",
    "    admin1_map_df = admin1_map_df.sort_values(['country_code', 'admin1_name_normalized']).reset_index(drop=True)\n",
    "    admin1_map_df.insert(0, 'admin1_id', admin1_map_df.index.astype(str))\n",
    "    print(f\"  Created Admin1 map with {len(admin1_map_df)} unique entries.\")\n",
    "\n",
    "    # --- Admin2 Mapping ---\n",
    "    print(\"Processing Admin2 names...\")\n",
    "    \n",
    "    # Merge the new admin1_id into the main dataframe to link admin2 to its parent admin1\n",
    "    # **FIXED**: Use left_on/right_on because the column names are different.\n",
    "    gdf = gdf.merge(\n",
    "        admin1_map_df[['admin1_name_normalized', 'country_code', 'admin1_id']],\n",
    "        left_on=['city_admin1_name_normalized', 'city_country_code'],\n",
    "        right_on=['admin1_name_normalized', 'country_code'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    admin2_data = []\n",
    "    # Filter for valid admin2 entries\n",
    "    admin2_gdf = gdf[gdf['city_admin2_name_normalized'].notna() & (gdf['city_admin2_name_normalized'] != '')].copy()\n",
    "    \n",
    "    # Group by normalized name and its parent admin1_id for uniqueness\n",
    "    grouped_admin2 = admin2_gdf.groupby(['city_admin2_name_normalized', 'admin1_id'])\n",
    "    \n",
    "    for (name_norm, admin1_id), group in grouped_admin2:\n",
    "        if pd.isna(admin1_id):\n",
    "            continue # Skip admin2 areas that couldn't be linked to a valid admin1\n",
    "            \n",
    "        # Choose display name and country code from the most populous city in the group\n",
    "        rep_row = group.loc[group['city_population'].fillna(0).idxmax()]\n",
    "        display_name = rep_row['city_admin2_name']\n",
    "        country_code = rep_row['city_country_code']\n",
    "        \n",
    "        # Collect all possible alternate names\n",
    "        alt_names = set()\n",
    "        alt_names.update(n for n in group['city_admin2_name'].dropna() if n.strip())\n",
    "        \n",
    "        # Add normalized versions\n",
    "        normalized_alts = {normalize_text(name) for name in alt_names}\n",
    "        alt_names.update(normalized_alts)\n",
    "\n",
    "        admin2_data.append({\n",
    "            'admin2_name_normalized': name_norm,\n",
    "            'admin2_name': display_name,\n",
    "            'admin1_id': str(admin1_id), # Ensure consistent string type\n",
    "            'country_code': country_code,\n",
    "            'admin2_alternatenames': sorted(list(alt_names))\n",
    "        })\n",
    "\n",
    "    admin2_map_df = pd.DataFrame(admin2_data)\n",
    "    # Sort for a stable index before assigning the ID\n",
    "    admin2_map_df = admin2_map_df.sort_values(['country_code', 'admin1_id', 'admin2_name_normalized']).reset_index(drop=True)\n",
    "    admin2_map_df.insert(0, 'admin2_id', admin2_map_df.index.astype(str))\n",
    "    print(f\"  Created Admin2 map with {len(admin2_map_df)} unique entries.\")\n",
    "\n",
    "    return admin1_map_df, admin2_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "153f68de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Admin Name Mapping Tables ---\n",
      "Processing Admin1 names...\n",
      "  Created Admin1 map with 3826 unique entries.\n",
      "Processing Admin2 names...\n",
      "  Created Admin2 map with 29052 unique entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin1_id</th>\n",
       "      <th>admin1_name_normalized</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin1_name</th>\n",
       "      <th>admin1_alternatenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>AD</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>[Andorra la Vella, andorra la vella]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>canillo</td>\n",
       "      <td>AD</td>\n",
       "      <td>Canillo</td>\n",
       "      <td>[Canillo, canillo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>encamp</td>\n",
       "      <td>AD</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>[Encamp, encamp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>escaldes-engordany</td>\n",
       "      <td>AD</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>[Escaldes-Engordany, escaldes-engordany]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>la massana</td>\n",
       "      <td>AD</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>[La Massana, la massana]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  admin1_id admin1_name_normalized country_code         admin1_name  \\\n",
       "0         0       andorra la vella           AD    Andorra la Vella   \n",
       "1         1                canillo           AD             Canillo   \n",
       "2         2                 encamp           AD              Encamp   \n",
       "3         3     escaldes-engordany           AD  Escaldes-Engordany   \n",
       "4         4             la massana           AD          La Massana   \n",
       "\n",
       "                      admin1_alternatenames  \n",
       "0      [Andorra la Vella, andorra la vella]  \n",
       "1                        [Canillo, canillo]  \n",
       "2                          [Encamp, encamp]  \n",
       "3  [Escaldes-Engordany, escaldes-engordany]  \n",
       "4                  [La Massana, la massana]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin2_id</th>\n",
       "      <th>admin2_name_normalized</th>\n",
       "      <th>admin2_name</th>\n",
       "      <th>admin1_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin2_alternatenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abu dhabi municipality</td>\n",
       "      <td>Abu Dhabi Municipality</td>\n",
       "      <td>7</td>\n",
       "      <td>AE</td>\n",
       "      <td>[Abu Dhabi Municipality, abu dhabi municipality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>al ain municipality</td>\n",
       "      <td>Al Ain Municipality</td>\n",
       "      <td>7</td>\n",
       "      <td>AE</td>\n",
       "      <td>[Al Ain Municipality, al ain municipality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>al dhafra</td>\n",
       "      <td>Al Dhafra</td>\n",
       "      <td>7</td>\n",
       "      <td>AE</td>\n",
       "      <td>[Al Dhafra, al dhafra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sector 1</td>\n",
       "      <td>Sector 1</td>\n",
       "      <td>9</td>\n",
       "      <td>AE</td>\n",
       "      <td>[Sector 1, sector 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sector 2</td>\n",
       "      <td>Sector 2</td>\n",
       "      <td>9</td>\n",
       "      <td>AE</td>\n",
       "      <td>[Sector 2, sector 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  admin2_id  admin2_name_normalized             admin2_name admin1_id  \\\n",
       "0         0  abu dhabi municipality  Abu Dhabi Municipality         7   \n",
       "1         1     al ain municipality     Al Ain Municipality         7   \n",
       "2         2               al dhafra               Al Dhafra         7   \n",
       "3         3                sector 1                Sector 1         9   \n",
       "4         4                sector 2                Sector 2         9   \n",
       "\n",
       "  country_code                             admin2_alternatenames  \n",
       "0           AE  [Abu Dhabi Municipality, abu dhabi municipality]  \n",
       "1           AE        [Al Ain Municipality, al ain municipality]  \n",
       "2           AE                            [Al Dhafra, al dhafra]  \n",
       "3           AE                              [Sector 1, sector 1]  \n",
       "4           AE                              [Sector 2, sector 2]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final GeoDataFrame with Admin IDs (as strings) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_name_normalized</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin1_id</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>city_admin2_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>greater_metro_name</th>\n",
       "      <th>greater_metro_id</th>\n",
       "      <th>greater_metro_in_country_name</th>\n",
       "      <th>greater_metro_in_country_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48e8d39f793285b5</td>\n",
       "      <td>Vila</td>\n",
       "      <td>vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>[Casas Vila, Vila, vila]</td>\n",
       "      <td>encamp</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "      <td>encamp</td>\n",
       "      <td>6176dbe2fec29734</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5f18e80ec393424</td>\n",
       "      <td>Soldeu</td>\n",
       "      <td>soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>[Sol'deu, Soldeu, soldeu, surudeu, swldw, Соль...</td>\n",
       "      <td>canillo</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "      <td>canillo</td>\n",
       "      <td>f92dba31f62d7810</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38132557d06759a4</td>\n",
       "      <td>Sispony</td>\n",
       "      <td>sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>[Sispony, sispony]</td>\n",
       "      <td>la massana</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "      <td>la massana</td>\n",
       "      <td>8334e238d8413912</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6223f9846326a714</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>el tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>[Ehl Tarter, El Tarter, El Tarter - Principau ...</td>\n",
       "      <td>canillo</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "      <td>canillo</td>\n",
       "      <td>f92dba31f62d7810</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8c4de62071e99deb</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>sant julia de loria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>[San Julia, San Julià, Sant Julia de Loria, Sa...</td>\n",
       "      <td>sant julia de loria</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "      <td>sant julia de loria</td>\n",
       "      <td>8c4de62071e99deb</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>e098c520e9b6b97a</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city_id            city_name city_name_normalized  city_latitude  \\\n",
       "0  48e8d39f793285b5                 Vila                 vila       42.53176   \n",
       "1  a5f18e80ec393424               Soldeu               soldeu       42.57688   \n",
       "2  38132557d06759a4              Sispony              sispony       42.53368   \n",
       "3  6223f9846326a714            El Tarter            el tarter       42.57952   \n",
       "4  8c4de62071e99deb  Sant Julià de Lòria  sant julia de loria       42.46372   \n",
       "\n",
       "   city_longitude city_country_code  city_population  \\\n",
       "0         1.56654                AD             1418   \n",
       "1         1.66769                AD              602   \n",
       "2         1.51613                AD              833   \n",
       "3         1.65362                AD             1052   \n",
       "4         1.49129                AD             8022   \n",
       "\n",
       "                                      alternatenames     city_admin1_name  \\\n",
       "0                           [Casas Vila, Vila, vila]               encamp   \n",
       "1  [Sol'deu, Soldeu, soldeu, surudeu, swldw, Соль...              canillo   \n",
       "2                                 [Sispony, sispony]           la massana   \n",
       "3  [Ehl Tarter, El Tarter, El Tarter - Principau ...              canillo   \n",
       "4  [San Julia, San Julià, Sant Julia de Loria, Sa...  sant julia de loria   \n",
       "\n",
       "  city_admin1_id city_admin2_name city_admin2_id                  geometry  \\\n",
       "0              2                                  POINT (1.56654 42.53176)   \n",
       "1              1                                  POINT (1.66769 42.57688)   \n",
       "2              4                                  POINT (1.51613 42.53368)   \n",
       "3              1                                  POINT (1.65362 42.57952)   \n",
       "4              6                                  POINT (1.49129 42.46372)   \n",
       "\n",
       "            metro_name          metro_id greater_metro_name  greater_metro_id  \\\n",
       "0               encamp  6176dbe2fec29734   andorra la vella  e098c520e9b6b97a   \n",
       "1              canillo  f92dba31f62d7810   andorra la vella  e098c520e9b6b97a   \n",
       "2           la massana  8334e238d8413912   andorra la vella  e098c520e9b6b97a   \n",
       "3              canillo  f92dba31f62d7810   andorra la vella  e098c520e9b6b97a   \n",
       "4  sant julia de loria  8c4de62071e99deb   andorra la vella  e098c520e9b6b97a   \n",
       "\n",
       "  greater_metro_in_country_name greater_metro_in_country_id    source  \n",
       "0              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "1              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "2              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "3              andorra la vella            e098c520e9b6b97a  geonames  \n",
       "4              andorra la vella            e098c520e9b6b97a  geonames  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved admin maps to 'c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\reverse_geocode3\\outputs/'\n",
      "Successfully saved final data to 'c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\reverse_geocode3\\outputs\\combined_cities_under500.geojson'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 2. Create the admin mapping tables\n",
    "admin1_map, admin2_map = create_admin_mappings(merged_gdf)\n",
    "display(admin1_map.head())\n",
    "display(admin2_map.head())\n",
    "\n",
    "# 3. Merge the new admin IDs into the final, clustered DataFrame\n",
    "# **FIXED**: The merges now use compound keys for accuracy.\n",
    "# Admin1 is unique by (name, country_code). Admin2 is unique by (name, admin1_id).\n",
    "\n",
    "# Merge Admin1 ID\n",
    "# Note: final_gdf_tuned['city_admin1_name'] is already normalized from the clustering step.\n",
    "final_gdf_tuned = final_gdf_tuned.merge(\n",
    "    admin1_map[['admin1_name_normalized', 'country_code', 'admin1_id']],\n",
    "    left_on=['city_admin1_name', 'city_country_code'],\n",
    "    right_on=['admin1_name_normalized', 'country_code'],\n",
    "    how='left'\n",
    ").rename(columns={'admin1_id': 'city_admin1_id'}).drop(columns=['admin1_name_normalized', 'country_code'])\n",
    "\n",
    "final_gdf_tuned['city_admin1_id'] = final_gdf_tuned['city_admin1_id'].fillna('')\n",
    "\n",
    "# Merge Admin2 ID\n",
    "# Note: final_gdf_tuned['city_admin2_name'] is also normalized.\n",
    "final_gdf_tuned = final_gdf_tuned.merge(\n",
    "    admin2_map[['admin2_name_normalized', 'admin1_id', 'admin2_id']],\n",
    "    left_on=['city_admin2_name', 'city_admin1_id'],\n",
    "    right_on=['admin2_name_normalized', 'admin1_id'],\n",
    "    how='left'\n",
    ").rename(columns={'admin2_id': 'city_admin2_id'}).drop(columns=['admin2_name_normalized', 'admin1_id'])\n",
    "\n",
    "# 4. Finalize data types and handle any remaining NaNs from the left merges\n",
    "# The admin IDs are created as strings, so NaNs from the merge will be float `np.nan`.\n",
    "# We fill them with an empty string for consistency.\n",
    "final_gdf_tuned['city_admin1_id'] = final_gdf_tuned['city_admin1_id'].fillna('')\n",
    "final_gdf_tuned['city_admin2_id'] = final_gdf_tuned['city_admin2_id'].fillna('')\n",
    "\n",
    "# 5. Reorder columns to place IDs next to their names\n",
    "final_cols_ordered = [\n",
    "    'city_id', 'city_name', 'city_name_normalized', 'city_latitude', 'city_longitude',\n",
    "    'city_country_code', 'city_population', 'alternatenames', \n",
    "    'city_admin1_name', 'city_admin1_id',\n",
    "    'city_admin2_name', 'city_admin2_id', \n",
    "    'geometry', 'metro_name', 'metro_id',\n",
    "    'greater_metro_name', 'greater_metro_id', 'greater_metro_in_country_name',\n",
    "    'greater_metro_in_country_id',  'source'\n",
    "]\n",
    "final_gdf_tuned = final_gdf_tuned[[col for col in final_cols_ordered if col in final_gdf_tuned.columns]]\n",
    "\n",
    "# 6. Display results to confirm the fix\n",
    "print(\"\\n--- Final GeoDataFrame with Admin IDs (as strings) ---\")\n",
    "display(final_gdf_tuned.head())\n",
    "\n",
    "\n",
    "# 7. Export all files (optional, uncomment to run)\n",
    "output_dir = 'c:\\\\Users\\\\larry\\\\Desktop\\\\Geoguessr ML Proj\\\\Geolocation-Project\\\\reverse_geocode3\\\\outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the admin maps to CSV\n",
    "if not include_all_worldcities:\n",
    "    admin1_map.to_csv(os.path.join(output_dir, 'admin1_map_under500.csv'), index=False)\n",
    "    admin2_map.to_csv(os.path.join(output_dir, 'admin2_map_under500.csv'), index=False)\n",
    "\n",
    "else:\n",
    "    admin1_map.to_csv(os.path.join(output_dir, 'admin1_map.csv'), index=False)\n",
    "    admin2_map.to_csv(os.path.join(output_dir, 'admin2_map.csv'), index=False)\n",
    "print(f\"\\nSuccessfully saved admin maps to '{output_dir}/'\")\n",
    "\n",
    "# Prepare and save the main GeoJSON\n",
    "final_gdf_for_export = final_gdf_tuned.copy()\n",
    "final_gdf_for_export['alternatenames'] = final_gdf_for_export['alternatenames'].apply(json.dumps)\n",
    "geojson_path = os.path.join(output_dir, 'combined_cities.geojson')\n",
    "if not include_all_worldcities:\n",
    "    geojson_path = os.path.join(output_dir, 'combined_cities_under500.geojson')\n",
    "\n",
    "final_gdf_for_export.to_file(geojson_path, driver='GeoJSON')\n",
    "print(f\"Successfully saved final data to '{geojson_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a0e056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_name_normalized</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin1_id</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>city_admin2_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>greater_metro_name</th>\n",
       "      <th>greater_metro_id</th>\n",
       "      <th>greater_metro_in_country_name</th>\n",
       "      <th>greater_metro_in_country_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123737</th>\n",
       "      <td>3e89082cad630aec</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>35.6895</td>\n",
       "      <td>139.69171</td>\n",
       "      <td>JP</td>\n",
       "      <td>9733276</td>\n",
       "      <td>[Edo, TYO, Tochiu, Tocio, Tokija, Tokijas, Tok...</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>1495</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (139.69171 35.6895)</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>3e89082cad630aec</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>3e89082cad630aec</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>3e89082cad630aec</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city_id city_name city_name_normalized  city_latitude  \\\n",
       "123737  3e89082cad630aec     Tokyo                tokyo        35.6895   \n",
       "\n",
       "        city_longitude city_country_code  city_population  \\\n",
       "123737       139.69171                JP          9733276   \n",
       "\n",
       "                                           alternatenames city_admin1_name  \\\n",
       "123737  [Edo, TYO, Tochiu, Tocio, Tokija, Tokijas, Tok...            tokyo   \n",
       "\n",
       "       city_admin1_id city_admin2_name city_admin2_id  \\\n",
       "123737           1495                                   \n",
       "\n",
       "                         geometry metro_name          metro_id  \\\n",
       "123737  POINT (139.69171 35.6895)      tokyo  3e89082cad630aec   \n",
       "\n",
       "       greater_metro_name  greater_metro_id greater_metro_in_country_name  \\\n",
       "123737              tokyo  3e89082cad630aec                         tokyo   \n",
       "\n",
       "       greater_metro_in_country_id    source  \n",
       "123737            3e89082cad630aec  geonames  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gdf_tuned[final_gdf_tuned[\"city_name\"] == \"Tokyo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c50123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>source</th>\n",
       "      <th>worldcities_admin1_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123737</th>\n",
       "      <td>3e89082cad630aec</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>35.6895</td>\n",
       "      <td>139.69171</td>\n",
       "      <td>JP</td>\n",
       "      <td>9733276</td>\n",
       "      <td>[Tocio, Edo, Tokió, tokyo, dong jing, টোকিও, d...</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (139.69171 35.6895)</td>\n",
       "      <td>geonames</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city_id city_name  city_latitude  city_longitude  \\\n",
       "123737  3e89082cad630aec     Tokyo        35.6895       139.69171   \n",
       "\n",
       "       city_country_code  city_population  \\\n",
       "123737                JP          9733276   \n",
       "\n",
       "                                           alternatenames city_admin1_name  \\\n",
       "123737  [Tocio, Edo, Tokió, tokyo, dong jing, টোকিও, d...            Tokyo   \n",
       "\n",
       "       city_admin2_name                   geometry    source  \\\n",
       "123737                   POINT (139.69171 35.6895)  geonames   \n",
       "\n",
       "       worldcities_admin1_name  \n",
       "123737                    None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_gdf[merged_gdf[\"city_name\"] == \"Tokyo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea85a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin1_id</th>\n",
       "      <th>admin1_name_normalized</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin1_name</th>\n",
       "      <th>admin1_alternatenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2259</td>\n",
       "      <td>manica</td>\n",
       "      <td>MZ</td>\n",
       "      <td>Manica</td>\n",
       "      <td>[Manica, manica]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     admin1_id admin1_name_normalized country_code admin1_name  \\\n",
       "2259      2259                 manica           MZ      Manica   \n",
       "\n",
       "     admin1_alternatenames  \n",
       "2259      [Manica, manica]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin1_map[admin1_map[\"admin1_id\"] == \"2259\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05096621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215880"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_gdf_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936afe9",
   "metadata": {},
   "source": [
    "Made direct changes to cities_500.txt:\n",
    "Some parentheses didn't have useful information, so they were removed\n",
    "downtown honolulu got changed with parentheses\n",
    "cites called Ninguno in geonames had to have changes from google maps\n",
    "worldcities NYC was explicitly renamed\n",
    "\n",
    "Cluster logic was only tested on phoenix and NY\n",
    "\n",
    "Should have 239360 cities on all combine\n",
    "215880 cities on under 500 combine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f046e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
