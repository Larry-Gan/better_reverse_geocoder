{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f958e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('c:\\\\Users\\\\larry\\\\Desktop\\\\Geoguessr ML Proj\\\\Geolocation-Project\\\\reverse_geocode3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd85d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81993a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading city data from GeoNames cities500.txt...\n",
      "Reading natural_earth_data/cities500.txt ...\n",
      "Loaded 215735 entries from GeoNames.\n",
      "\n",
      "--- Loading Admin Name Mappings ---\n",
      "Loading Admin1 names from natural_earth_data/admin1CodesASCII.txt...\n",
      "Loaded 3893 Admin1 name mappings.\n",
      "Loading Admin2 names from natural_earth_data/admin2Codes.txt...\n",
      "Loaded 47356 Admin2 name mappings.\n",
      "\n",
      "--- Mapping Admin Codes to Names ---\n",
      "Admin1 names mapped.\n",
      "Admin2 names mapped.\n",
      "Converting GeoNames data to GeoDataFrame...\n",
      "Building KDTree for GeoNames cities...\n",
      "KDTree built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "215735"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, _ = data_loader.load_cities_and_build_kdtree_from_geonames()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e684630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48059"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('natural_earth_data/worldcities.csv')\n",
    "df2['population'] = df2['population'].fillna(0)\n",
    "df2.loc[14, \"city\"] = \"New York City\"\n",
    "df2.loc[14, \"city_ascii\"] = \"New York City\"\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5b5e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting OPTICS Clustering Process ---\n",
      "Step 1: Preparing and standardizing data from both sources...\n",
      "  Combined dataset has 263629 unique cities.\n",
      "\n",
      "Step 2: Projecting data and running OPTICS clustering...\n",
      "  Parameters: max_eps=20000m, min_samples=5, xi=0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 156\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gdf_final\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# --- Example Usage ---\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Assuming 'df' and 'df2' are pre-loaded with the specified column structures.\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m final_clustered_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_cities_with_optics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdf_geonames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_worldcities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf2\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# print(\"\\nExample: Results for New York City Area\")\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Check for a major city name that exists in your df2 data\u001b[39;00m\n\u001b[0;32m    163\u001b[0m nyc_area \u001b[38;5;241m=\u001b[39m final_clustered_gdf[final_clustered_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetro_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew York\u001b[39m\u001b[38;5;124m'\u001b[39m] \n",
      "Cell \u001b[1;32mIn[6], line 97\u001b[0m, in \u001b[0;36mcluster_cities_with_optics\u001b[1;34m(gdf_geonames, df_worldcities, max_eps_meters, min_samples, xi)\u001b[0m\n\u001b[0;32m     94\u001b[0m coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(gdf_all_cities_proj\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mx, gdf_all_cities_proj\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39my)))\n\u001b[0;32m     96\u001b[0m optics \u001b[38;5;241m=\u001b[39m OPTICS(min_samples\u001b[38;5;241m=\u001b[39mmin_samples, max_eps\u001b[38;5;241m=\u001b[39mmax_eps_meters, xi\u001b[38;5;241m=\u001b[39mxi, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m \u001b[43moptics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m gdf_all_cities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optics\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m    100\u001b[0m num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(optics\u001b[38;5;241m.\u001b[39mlabels_[optics\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:353\u001b[0m, in \u001b[0;36mOPTICS.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    345\u001b[0m         X\u001b[38;5;241m.\u001b[39msetdiag(X\u001b[38;5;241m.\u001b[39mdiagonal())\n\u001b[0;32m    346\u001b[0m memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n\u001b[0;32m    348\u001b[0m (\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordering_,\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore_distances_,\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreachability_,\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredecessor_,\n\u001b[1;32m--> 353\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_optics_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleaf_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaf_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# Extract clusters from the calculated orders and reachability\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:650\u001b[0m, in \u001b[0;36mcompute_optics_graph\u001b[1;34m(X, min_samples, max_eps, metric, p, metric_params, algorithm, leaf_size, n_jobs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     ordering[ordering_idx] \u001b[38;5;241m=\u001b[39m point\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m core_distances_[point] \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39minf:\n\u001b[1;32m--> 650\u001b[0m         \u001b[43m_set_reach_dist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcore_distances_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_distances_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreachability_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreachability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredecessor_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredecessor_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoint_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnbrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misinf(reachability_)):\n\u001b[0;32m    664\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    665\u001b[0m         (\n\u001b[0;32m    666\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll reachability values are inf. Set a larger\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    670\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:691\u001b[0m, in \u001b[0;36m_set_reach_dist\u001b[1;34m(core_distances_, reachability_, predecessor_, point_index, processed, X, nbrs, metric, metric_params, p, max_eps)\u001b[0m\n\u001b[0;32m    687\u001b[0m P \u001b[38;5;241m=\u001b[39m X[point_index : point_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    688\u001b[0m \u001b[38;5;66;03m# Assume that radius_neighbors is faster without distances\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# and we don't need all distances, nevertheless, this means\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;66;03m# we may be doing some work twice.\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnbrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# Getting indices of neighbors that have not been processed\u001b[39;00m\n\u001b[0;32m    694\u001b[0m unproc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcompress(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39mtake(processed, indices), indices)\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:1277\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1275\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m   1276\u001b[0m delayed_query \u001b[38;5;241m=\u001b[39m delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree\u001b[38;5;241m.\u001b[39mquery_radius)\n\u001b[1;32m-> 1277\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[0;32m   1282\u001b[0m     neigh_ind, neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mchunked_results))\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_optics(\n",
    "    gdf_geonames, \n",
    "    df_worldcities, \n",
    "    max_eps_meters=20000, \n",
    "    min_samples=5, \n",
    "    xi=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies metropolitan areas by clustering cities using the OPTICS algorithm.\n",
    "\n",
    "    This function replaces a fixed-radius search with a density-based approach\n",
    "    to more accurately group boroughs and suburbs with their parent cities.\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary GeoDataFrame of cities (your 'df').\n",
    "                                         Must include columns: 'city_name', 'city_latitude',\n",
    "                                         'city_longitude', 'city_population', 'geometry'.\n",
    "        df_worldcities (pd.DataFrame): Your secondary DataFrame of major cities (your 'df2').\n",
    "                                       Must include columns: 'city_ascii', 'lat',\n",
    "                                       'lng', 'population', 'id'.\n",
    "        max_eps_meters (int): The maximum distance (in meters) between two samples for them\n",
    "                              to be considered as in the same neighborhood. This is an\n",
    "                              upper bound for OPTICS performance, not a strict radius.\n",
    "        min_samples (int): The number of samples in a neighborhood for a point to be\n",
    "                           considered as a core point. This is the primary density parameter.\n",
    "        xi (float): Determines the minimum steepness on the reachability plot that \n",
    "                    constitutes a cluster boundary. Between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original gdf_geonames with two new columns:\n",
    "                          'metro_id' (the 'id' from df2 of the representative city) and\n",
    "                          'metro_name' (the name of the representative city).\n",
    "    \"\"\"\n",
    "    print(\"--- Starting OPTICS Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data ---\n",
    "    print(\"Step 1: Preparing and standardizing data from both sources...\")\n",
    "\n",
    "    # Standardize GeoNames data (your 'df')\n",
    "    gdf_geonames_std = gdf_geonames[['city_name', 'city_latitude', 'city_longitude', 'city_population', 'geometry']].copy()\n",
    "    # Create a temporary unique ID from the index to merge back later\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    # Rename columns to a standard internal format\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude',\n",
    "        'city_longitude': 'longitude',\n",
    "        'city_population': 'population'\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "    \n",
    "    # Standardize and create GeoDataFrame for worldcities (your 'df2')\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    # Rename columns to the same standard internal format\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name',\n",
    "        'lat': 'latitude',\n",
    "        'lng': 'longitude',\n",
    "        'id': 'original_id' # Use the worldcities ID as its unique identifier\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Combine into a single GeoDataFrame using standardized columns\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    \n",
    "    # Drop duplicates, keeping the one from worldcities if a conflict exists (as it's curated)\n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "    # --- Step 2: Project Data and Run OPTICS ---\n",
    "    print(\"\\nStep 2: Projecting data and running OPTICS clustering...\")\n",
    "    print(f\"  Parameters: max_eps={max_eps_meters}m, min_samples={min_samples}, xi={xi}\")\n",
    "    \n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "    \n",
    "    optics = OPTICS(min_samples=min_samples, max_eps=max_eps_meters, xi=xi, n_jobs=-1)\n",
    "    optics.fit(coords)\n",
    "    \n",
    "    gdf_all_cities['cluster_id'] = optics.labels_\n",
    "    num_clusters = len(np.unique(optics.labels_[optics.labels_ != -1]))\n",
    "    num_noise = np.sum(optics.labels_ == -1)\n",
    "    print(f\"  OPTICS found {num_clusters} clusters and {num_noise} noise points.\")\n",
    "\n",
    "    # --- Step 3: Identify Representative City for Each Cluster ---\n",
    "    print(\"\\nStep 3: Identifying the most populous representative city for each cluster...\")\n",
    "    \n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Find the representative (most populous city) for each cluster_id\n",
    "    representatives = gdf_all_cities[gdf_all_cities['cluster_id'] != -1].loc[\n",
    "        gdf_all_cities.groupby('cluster_id')['population'].idxmax()\n",
    "    ]\n",
    "    \n",
    "    # Create a map from cluster_id to the representative's name and ID\n",
    "    representatives_map_df = representatives[['cluster_id', 'city_name', 'original_id']].copy()\n",
    "    representatives_map_df.rename(columns={'city_name': 'metro_name', 'original_id': 'metro_id'}, inplace=True)\n",
    "    \n",
    "    # --- Step 4: Map Representatives Back to Original GeoNames Data ---\n",
    "    print(\"\\nStep 4: Merging cluster results back into the original 'df' DataFrame...\")\n",
    "    \n",
    "    # First, add the original_id to the main combined list so we can find it\n",
    "    gdf_all_cities_with_id = gdf_all_cities.merge(gdf_geonames_std[['original_id', 'geometry']], on='geometry')\n",
    "\n",
    "    # Merge the cluster information back to the main city list\n",
    "    gdf_all_cities_merged = gdf_all_cities_with_id.merge(\n",
    "        representatives_map_df, on='cluster_id', how='left'\n",
    "    )\n",
    "    \n",
    "    # For noise points (not in a cluster), they represent themselves\n",
    "    is_noise = gdf_all_cities_merged['metro_name'].isna()\n",
    "    gdf_all_cities_merged.loc[is_noise, 'metro_name'] = gdf_all_cities_merged.loc[is_noise, 'city_name']\n",
    "    gdf_all_cities_merged.loc[is_noise, 'metro_id'] = gdf_all_cities_merged.loc[is_noise, 'original_id_x'] # Use its own id\n",
    "    \n",
    "    # Filter for the original data source and the columns we need to add back\n",
    "    final_cols_to_merge = gdf_all_cities_merged[gdf_all_cities_merged['source'] == 'geonames'][['original_id_x', 'metro_id', 'metro_name']]\n",
    "    final_cols_to_merge.rename(columns={'original_id_x': 'original_id'}, inplace=True)\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    # Merge the new metro columns back to the original gdf_geonames using the index\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"\\n--- OPTICS Process Complete! ---\")\n",
    "    print(f\"Final dataset contains {len(gdf_final)} cities, enriched with metro area information.\")\n",
    "    \n",
    "    return gdf_final\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Assuming 'df' and 'df2' are pre-loaded with the specified column structures.\n",
    "\n",
    "final_clustered_gdf = cluster_cities_with_optics(\n",
    "    gdf_geonames=df, \n",
    "    df_worldcities=df2\n",
    ")\n",
    "\n",
    "# print(\"\\nExample: Results for New York City Area\")\n",
    "# Check for a major city name that exists in your df2 data\n",
    "nyc_area = final_clustered_gdf[final_clustered_gdf['metro_name'] == 'New York'] \n",
    "print(nyc_area[['city_name', 'metro_name']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a21013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting HDBSCAN Clustering Process ---\n",
      "Step 1: Preparing and standardizing data from both sources...\n",
      "  Combined dataset has 263629 unique cities.\n",
      "\n",
      "Step 2: Projecting data and running HDBSCAN clustering...\n",
      "  Parameters: min_cluster_size=5\n",
      "  Starting hdbscan.fit()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HDBSCAN found 7771 clusters and 94908 noise points.\n",
      "\n",
      "Step 3: Identifying the most populous representative city for each cluster...\n",
      "\n",
      "Step 4: Merging cluster results back into the original 'df' DataFrame...\n",
      "\n",
      "--- HDBSCAN Process Complete! ---\n",
      "Final dataset contains 215735 cities, enriched with metro area information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "import hdbscan # Import the hdbscan library\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_hdbscan(\n",
    "    gdf_geonames, \n",
    "    df_worldcities,\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies metropolitan areas by clustering cities using the HDBSCAN algorithm.\n",
    "    This is often faster than OPTICS and requires less parameter tuning.\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary GeoDataFrame of cities (your 'df').\n",
    "                                         Must include columns: 'city_name', 'city_latitude',\n",
    "                                         'city_longitude', 'city_population', 'geometry'.\n",
    "        df_worldcities (pd.DataFrame): Your secondary DataFrame of major cities (your 'df2').\n",
    "                                       Must include columns: 'city_ascii', 'lat',\n",
    "                                       'lng', 'population', 'id'.\n",
    "        min_samples (int): The number of samples in a neighborhood for a point to be\n",
    "                           considered as a core point. This is the primary density parameter.\n",
    "        xi (float): Determines the minimum steepness on the reachability plot that \n",
    "                    constitutes a cluster boundary. Between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original gdf_geonames with two new columns:\n",
    "                          'metro_id' (the 'id' from df2 of the representative city) and\n",
    "                          'metro_name' (the name of the representative city).\n",
    "    \"\"\"\n",
    "    print(\"--- Starting HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data ---\n",
    "    print(\"Step 1: Preparing and standardizing data from both sources...\")\n",
    "\n",
    "    # Standardize GeoNames data (your 'df')\n",
    "    gdf_geonames_std = gdf_geonames[['city_name', 'city_latitude', 'city_longitude', 'city_population', 'geometry']].copy()\n",
    "    # Create a temporary unique ID from the index to merge back later\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    # Rename columns to a standard internal format\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude',\n",
    "        'city_longitude': 'longitude',\n",
    "        'city_population': 'population'\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "    \n",
    "    # Standardize and create GeoDataFrame for worldcities (your 'df2')\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    # Rename columns to the same standard internal format\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name',\n",
    "        'lat': 'latitude',\n",
    "        'lng': 'longitude',\n",
    "        'id': 'original_id' # Use the worldcities ID as its unique identifier\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Combine into a single GeoDataFrame using standardized columns\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    \n",
    "    # Drop duplicates, keeping the one from worldcities if a conflict exists (as it's curated)\n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "     # --- Step 2: Project Data and Run HDBSCAN ---\n",
    "    print(\"\\nStep 2: Projecting data and running HDBSCAN clustering...\")\n",
    "    print(f\"  Parameters: min_cluster_size={min_cluster_size}\")\n",
    "\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "\n",
    "    print(\"  Starting hdbscan.fit()...\")\n",
    "\n",
    "    # NOTE: HDBSCAN uses different parameters.\n",
    "    # min_cluster_size is the most important one.\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples, # Often left as None to default to min_cluster_size\n",
    "        metric='euclidean',\n",
    "        # HDBSCAN has a prediction_data=True option for advanced use\n",
    "    )\n",
    "    clusterer.fit(coords)\n",
    "        \n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    num_clusters = len(np.unique(clusterer.labels_[clusterer.labels_ != -1]))\n",
    "    num_noise = np.sum(clusterer.labels_ == -1)\n",
    "    print(f\"  HDBSCAN found {num_clusters} clusters and {num_noise} noise points.\")\n",
    "\n",
    "    # --- Step 3: Identify Representative City for Each Cluster ---\n",
    "    print(\"\\nStep 3: Identifying the most populous representative city for each cluster...\")\n",
    "    \n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # First, get the index labels of the most populous city for EACH cluster_id\n",
    "    # This operates on the full dataframe.\n",
    "    idx_of_representatives = gdf_all_cities.groupby('cluster_id')['population'].idxmax()\n",
    "\n",
    "    # Now, use .loc on the full dataframe to select these rows\n",
    "    representatives = gdf_all_cities.loc[idx_of_representatives].copy()\n",
    "\n",
    "    # The result from idxmax() includes a row for the -1 \"noise\" cluster. We don't need it.\n",
    "    representatives = representatives[representatives['cluster_id'] != -1]\n",
    "    \n",
    "    # Create a map from cluster_id to the representative's name and ID\n",
    "    representatives_map_df = representatives[['cluster_id', 'city_name', 'original_id']].copy()\n",
    "    representatives_map_df.rename(columns={'city_name': 'metro_name', 'original_id': 'metro_id'}, inplace=True)\n",
    "    \n",
    "    # --- Step 4: Map Representatives Back to Original GeoNames Data ---\n",
    "    print(\"\\nStep 4: Merging cluster results back into the original 'df' DataFrame...\")\n",
    "    \n",
    "    # First, add the original_id to the main combined list so we can find it\n",
    "    gdf_all_cities_with_id = gdf_all_cities.merge(gdf_geonames_std[['original_id', 'geometry']], on='geometry')\n",
    "\n",
    "    # Merge the cluster information back to the main city list\n",
    "    gdf_all_cities_merged = gdf_all_cities_with_id.merge(\n",
    "        representatives_map_df, on='cluster_id', how='left'\n",
    "    )\n",
    "    \n",
    "    # For noise points (not in a cluster), they represent themselves\n",
    "    is_noise = gdf_all_cities_merged['metro_name'].isna()\n",
    "    gdf_all_cities_merged.loc[is_noise, 'metro_name'] = gdf_all_cities_merged.loc[is_noise, 'city_name']\n",
    "    gdf_all_cities_merged.loc[is_noise, 'metro_id'] = gdf_all_cities_merged.loc[is_noise, 'original_id_x'] # Use its own id\n",
    "    \n",
    "    # Filter for the original data source and the columns we need to add back\n",
    "    final_cols_to_merge = gdf_all_cities_merged[gdf_all_cities_merged['source'] == 'geonames'][['original_id_x', 'metro_id', 'metro_name']]\n",
    "    final_cols_to_merge.rename(columns={'original_id_x': 'original_id'}, inplace=True)\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    # Merge the new metro columns back to the original gdf_geonames using the index\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"\\n--- HDBSCAN Process Complete! ---\")\n",
    "    print(f\"Final dataset contains {len(gdf_final)} cities, enriched with metro area information.\")\n",
    "    \n",
    "    return gdf_final\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Assuming 'df' and 'df2' are pre-loaded with the specified column structures.\n",
    "\n",
    "final_clustered_gdf = cluster_cities_with_hdbscan(\n",
    "    gdf_geonames=df, \n",
    "    df_worldcities=df2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d9fc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>metro_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [city_name, city_latitude, city_longitude, city_country_code, city_population, city_admin1_name, city_admin2_name, geometry, metro_id, metro_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"\\nExample: Results for New York City Area\")\n",
    "# Check for a major city name that exists in your df2 data\n",
    "nyc_area = final_clustered_gdf[final_clustered_gdf['metro_name'] == 'New York'] \n",
    "nyc_area.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25713ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>metro_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Sant Juli de Lria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>Sant Juli de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>AD</td>\n",
       "      <td>2363</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.73361 42.54277)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>Ordino</td>\n",
       "      <td>42.55623</td>\n",
       "      <td>1.53319</td>\n",
       "      <td>AD</td>\n",
       "      <td>3066</td>\n",
       "      <td>Ordino</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.53319 42.55623)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>AD</td>\n",
       "      <td>15853</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.53414 42.50729)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>la Massana</td>\n",
       "      <td>42.54499</td>\n",
       "      <td>1.51483</td>\n",
       "      <td>AD</td>\n",
       "      <td>7211</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51483 42.54499)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>l'Aldosa</td>\n",
       "      <td>42.54391</td>\n",
       "      <td>1.52289</td>\n",
       "      <td>AD</td>\n",
       "      <td>594</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52289 42.54391)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>Encamp</td>\n",
       "      <td>42.53474</td>\n",
       "      <td>1.58014</td>\n",
       "      <td>AD</td>\n",
       "      <td>11223</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.58014 42.53474)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>Canillo</td>\n",
       "      <td>42.56760</td>\n",
       "      <td>1.59756</td>\n",
       "      <td>AD</td>\n",
       "      <td>3292</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.59756 42.5676)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>Arinsal</td>\n",
       "      <td>42.57205</td>\n",
       "      <td>1.48453</td>\n",
       "      <td>AD</td>\n",
       "      <td>1419</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.48453 42.57205)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>Anys</td>\n",
       "      <td>42.53465</td>\n",
       "      <td>1.52510</td>\n",
       "      <td>AD</td>\n",
       "      <td>1006</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.5251 42.53465)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>AD</td>\n",
       "      <td>20430</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52109 42.50779)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>Aixirivall</td>\n",
       "      <td>42.46245</td>\n",
       "      <td>1.50209</td>\n",
       "      <td>AD</td>\n",
       "      <td>1041</td>\n",
       "      <td>Sant Juli de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.50209 42.46245)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>Warsn</td>\n",
       "      <td>25.16744</td>\n",
       "      <td>55.40708</td>\n",
       "      <td>AE</td>\n",
       "      <td>108759</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.40708 25.16744)</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city_name  city_latitude  city_longitude city_country_code  \\\n",
       "0.0                  Vila       42.53176         1.56654                AD   \n",
       "1.0                Soldeu       42.57688         1.66769                AD   \n",
       "2.0               Sispony       42.53368         1.51613                AD   \n",
       "3.0             El Tarter       42.57952         1.65362                AD   \n",
       "4.0   Sant Juli de Lria       42.46372         1.49129                AD   \n",
       "5.0        Pas de la Casa       42.54277         1.73361                AD   \n",
       "6.0                Ordino       42.55623         1.53319                AD   \n",
       "7.0          les Escaldes       42.50729         1.53414                AD   \n",
       "8.0            la Massana       42.54499         1.51483                AD   \n",
       "9.0              l'Aldosa       42.54391         1.52289                AD   \n",
       "10.0               Encamp       42.53474         1.58014                AD   \n",
       "11.0              Canillo       42.56760         1.59756                AD   \n",
       "12.0              Arinsal       42.57205         1.48453                AD   \n",
       "13.0                Anys       42.53465         1.52510                AD   \n",
       "14.0     Andorra la Vella       42.50779         1.52109                AD   \n",
       "15.0           Aixirivall       42.46245         1.50209                AD   \n",
       "16.0              Warsn       25.16744        55.40708                AE   \n",
       "\n",
       "      city_population     city_admin1_name city_admin2_name  \\\n",
       "0.0              1418               Encamp                    \n",
       "1.0               602              Canillo                    \n",
       "2.0               833           La Massana                    \n",
       "3.0              1052              Canillo                    \n",
       "4.0              8022  Sant Juli de Loria                    \n",
       "5.0              2363               Encamp                    \n",
       "6.0              3066               Ordino                    \n",
       "7.0             15853   Escaldes-Engordany                    \n",
       "8.0              7211           La Massana                    \n",
       "9.0               594           La Massana                    \n",
       "10.0            11223               Encamp                    \n",
       "11.0             3292              Canillo                    \n",
       "12.0             1419           La Massana                    \n",
       "13.0             1006           La Massana                    \n",
       "14.0            20430     Andorra la Vella                    \n",
       "15.0             1041  Sant Juli de Loria                    \n",
       "16.0           108759                Dubai                    \n",
       "\n",
       "                       geometry      metro_id        metro_name  \n",
       "0.0    POINT (1.56654 42.53176)  1.020829e+09  Andorra la Vella  \n",
       "1.0    POINT (1.66769 42.57688)  1.020829e+09  Andorra la Vella  \n",
       "2.0    POINT (1.51613 42.53368)  1.020829e+09  Andorra la Vella  \n",
       "3.0    POINT (1.65362 42.57952)  1.020829e+09  Andorra la Vella  \n",
       "4.0    POINT (1.49129 42.46372)  1.020829e+09  Andorra la Vella  \n",
       "5.0    POINT (1.73361 42.54277)  1.020829e+09  Andorra la Vella  \n",
       "6.0    POINT (1.53319 42.55623)  1.020829e+09  Andorra la Vella  \n",
       "7.0    POINT (1.53414 42.50729)  1.020829e+09  Andorra la Vella  \n",
       "8.0    POINT (1.51483 42.54499)  1.020829e+09  Andorra la Vella  \n",
       "9.0    POINT (1.52289 42.54391)  1.020829e+09  Andorra la Vella  \n",
       "10.0   POINT (1.58014 42.53474)  1.020829e+09  Andorra la Vella  \n",
       "11.0    POINT (1.59756 42.5676)  1.020829e+09  Andorra la Vella  \n",
       "12.0   POINT (1.48453 42.57205)  1.020829e+09  Andorra la Vella  \n",
       "13.0    POINT (1.5251 42.53465)  1.020829e+09  Andorra la Vella  \n",
       "14.0   POINT (1.52109 42.50779)  1.020829e+09  Andorra la Vella  \n",
       "15.0   POINT (1.50209 42.46245)  1.020829e+09  Andorra la Vella  \n",
       "16.0  POINT (55.40708 25.16744)  2.900000e+01             Dubai  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clustered_gdf.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba776ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>AD</td>\n",
       "      <td>20430</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52109 42.50779)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city_name  city_latitude  city_longitude city_country_code  \\\n",
       "14  Andorra la Vella       42.50779         1.52109                AD   \n",
       "\n",
       "    city_population  city_admin1_name city_admin2_name  \\\n",
       "14            20430  Andorra la Vella                    \n",
       "\n",
       "                    geometry  \n",
       "14  POINT (1.52109 42.50779)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"city_name\"] == \"Andorra la Vella\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c12a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sant Juli de Lria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>Sant Juli de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>AD</td>\n",
       "      <td>2363</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.73361 42.54277)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ordino</td>\n",
       "      <td>42.55623</td>\n",
       "      <td>1.53319</td>\n",
       "      <td>AD</td>\n",
       "      <td>3066</td>\n",
       "      <td>Ordino</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.53319 42.55623)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>AD</td>\n",
       "      <td>15853</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.53414 42.50729)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>la Massana</td>\n",
       "      <td>42.54499</td>\n",
       "      <td>1.51483</td>\n",
       "      <td>AD</td>\n",
       "      <td>7211</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51483 42.54499)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l'Aldosa</td>\n",
       "      <td>42.54391</td>\n",
       "      <td>1.52289</td>\n",
       "      <td>AD</td>\n",
       "      <td>594</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52289 42.54391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Encamp</td>\n",
       "      <td>42.53474</td>\n",
       "      <td>1.58014</td>\n",
       "      <td>AD</td>\n",
       "      <td>11223</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.58014 42.53474)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Canillo</td>\n",
       "      <td>42.56760</td>\n",
       "      <td>1.59756</td>\n",
       "      <td>AD</td>\n",
       "      <td>3292</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.59756 42.5676)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arinsal</td>\n",
       "      <td>42.57205</td>\n",
       "      <td>1.48453</td>\n",
       "      <td>AD</td>\n",
       "      <td>1419</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.48453 42.57205)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anys</td>\n",
       "      <td>42.53465</td>\n",
       "      <td>1.52510</td>\n",
       "      <td>AD</td>\n",
       "      <td>1006</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.5251 42.53465)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>AD</td>\n",
       "      <td>20430</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52109 42.50779)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aixirivall</td>\n",
       "      <td>42.46245</td>\n",
       "      <td>1.50209</td>\n",
       "      <td>AD</td>\n",
       "      <td>1041</td>\n",
       "      <td>Sant Juli de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.50209 42.46245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Warsn</td>\n",
       "      <td>25.16744</td>\n",
       "      <td>55.40708</td>\n",
       "      <td>AE</td>\n",
       "      <td>108759</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.40708 25.16744)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Umm Suqaym</td>\n",
       "      <td>25.15491</td>\n",
       "      <td>55.21015</td>\n",
       "      <td>AE</td>\n",
       "      <td>16459</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.21015 25.15491)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>25.56473</td>\n",
       "      <td>55.55517</td>\n",
       "      <td>AE</td>\n",
       "      <td>62747</td>\n",
       "      <td>Imrat Umm al Qaywayn</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.55517 25.56473)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ar Rshidyah</td>\n",
       "      <td>25.22499</td>\n",
       "      <td>55.38947</td>\n",
       "      <td>AE</td>\n",
       "      <td>38425</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.38947 25.22499)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>25.78953</td>\n",
       "      <td>55.94320</td>\n",
       "      <td>AE</td>\n",
       "      <td>351943</td>\n",
       "      <td>Ras al Khaymah</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.9432 25.78953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Muzayri</td>\n",
       "      <td>23.14355</td>\n",
       "      <td>53.78810</td>\n",
       "      <td>AE</td>\n",
       "      <td>10000</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>Al Dhafra</td>\n",
       "      <td>POINT (53.7881 23.14355)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Murba</td>\n",
       "      <td>25.27623</td>\n",
       "      <td>56.36256</td>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sharjah</td>\n",
       "      <td></td>\n",
       "      <td>POINT (56.36256 25.27623)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Maf</td>\n",
       "      <td>24.81089</td>\n",
       "      <td>56.10657</td>\n",
       "      <td>AE</td>\n",
       "      <td>8988</td>\n",
       "      <td>Ajman</td>\n",
       "      <td></td>\n",
       "      <td>POINT (56.10657 24.81089)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zayed City</td>\n",
       "      <td>23.65416</td>\n",
       "      <td>53.70522</td>\n",
       "      <td>AE</td>\n",
       "      <td>63482</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>Al Dhafra</td>\n",
       "      <td>POINT (53.70522 23.65416)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Khawr Fakkn</td>\n",
       "      <td>25.33132</td>\n",
       "      <td>56.34199</td>\n",
       "      <td>AE</td>\n",
       "      <td>40677</td>\n",
       "      <td>Sharjah</td>\n",
       "      <td></td>\n",
       "      <td>POINT (56.34199 25.33132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kalb</td>\n",
       "      <td>25.05130</td>\n",
       "      <td>56.35422</td>\n",
       "      <td>AE</td>\n",
       "      <td>37545</td>\n",
       "      <td>Sharjah</td>\n",
       "      <td></td>\n",
       "      <td>POINT (56.35422 25.0513)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jumayr</td>\n",
       "      <td>25.20795</td>\n",
       "      <td>55.24969</td>\n",
       "      <td>AE</td>\n",
       "      <td>39080</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.24969 25.20795)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Al Jazrah al amr</td>\n",
       "      <td>25.70910</td>\n",
       "      <td>55.80772</td>\n",
       "      <td>AE</td>\n",
       "      <td>10190</td>\n",
       "      <td>Ras al Khaymah</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.80772 25.7091)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dubai</td>\n",
       "      <td>25.07725</td>\n",
       "      <td>55.30927</td>\n",
       "      <td>AE</td>\n",
       "      <td>3478300</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.30927 25.07725)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city_name  city_latitude  city_longitude city_country_code  \\\n",
       "0                   Vila       42.53176         1.56654                AD   \n",
       "1                 Soldeu       42.57688         1.66769                AD   \n",
       "2                Sispony       42.53368         1.51613                AD   \n",
       "3              El Tarter       42.57952         1.65362                AD   \n",
       "4    Sant Juli de Lria       42.46372         1.49129                AD   \n",
       "5         Pas de la Casa       42.54277         1.73361                AD   \n",
       "6                 Ordino       42.55623         1.53319                AD   \n",
       "7           les Escaldes       42.50729         1.53414                AD   \n",
       "8             la Massana       42.54499         1.51483                AD   \n",
       "9               l'Aldosa       42.54391         1.52289                AD   \n",
       "10                Encamp       42.53474         1.58014                AD   \n",
       "11               Canillo       42.56760         1.59756                AD   \n",
       "12               Arinsal       42.57205         1.48453                AD   \n",
       "13                 Anys       42.53465         1.52510                AD   \n",
       "14      Andorra la Vella       42.50779         1.52109                AD   \n",
       "15            Aixirivall       42.46245         1.50209                AD   \n",
       "16               Warsn       25.16744        55.40708                AE   \n",
       "17            Umm Suqaym       25.15491        55.21015                AE   \n",
       "18    Umm Al Quwain City       25.56473        55.55517                AE   \n",
       "19         Ar Rshidyah       25.22499        55.38947                AE   \n",
       "20   Ras Al Khaimah City       25.78953        55.94320                AE   \n",
       "21              Muzayri       23.14355        53.78810                AE   \n",
       "22                Murba       25.27623        56.36256                AE   \n",
       "23                Maf       24.81089        56.10657                AE   \n",
       "24            Zayed City       23.65416        53.70522                AE   \n",
       "25          Khawr Fakkn       25.33132        56.34199                AE   \n",
       "26                 Kalb       25.05130        56.35422                AE   \n",
       "27               Jumayr       25.20795        55.24969                AE   \n",
       "28  Al Jazrah al amr       25.70910        55.80772                AE   \n",
       "29                 Dubai       25.07725        55.30927                AE   \n",
       "\n",
       "    city_population       city_admin1_name city_admin2_name  \\\n",
       "0              1418                 Encamp                    \n",
       "1               602                Canillo                    \n",
       "2               833             La Massana                    \n",
       "3              1052                Canillo                    \n",
       "4              8022    Sant Juli de Loria                    \n",
       "5              2363                 Encamp                    \n",
       "6              3066                 Ordino                    \n",
       "7             15853     Escaldes-Engordany                    \n",
       "8              7211             La Massana                    \n",
       "9               594             La Massana                    \n",
       "10            11223                 Encamp                    \n",
       "11             3292                Canillo                    \n",
       "12             1419             La Massana                    \n",
       "13             1006             La Massana                    \n",
       "14            20430       Andorra la Vella                    \n",
       "15             1041    Sant Juli de Loria                    \n",
       "16           108759                  Dubai                    \n",
       "17            16459                  Dubai                    \n",
       "18            62747  Imrat Umm al Qaywayn                    \n",
       "19            38425                  Dubai                    \n",
       "20           351943        Ras al Khaymah                    \n",
       "21            10000              Abu Dhabi        Al Dhafra   \n",
       "22             2000                Sharjah                    \n",
       "23             8988                  Ajman                    \n",
       "24            63482              Abu Dhabi        Al Dhafra   \n",
       "25            40677                Sharjah                    \n",
       "26            37545                Sharjah                    \n",
       "27            39080                  Dubai                    \n",
       "28            10190        Ras al Khaymah                    \n",
       "29          3478300                  Dubai                    \n",
       "\n",
       "                     geometry  \n",
       "0    POINT (1.56654 42.53176)  \n",
       "1    POINT (1.66769 42.57688)  \n",
       "2    POINT (1.51613 42.53368)  \n",
       "3    POINT (1.65362 42.57952)  \n",
       "4    POINT (1.49129 42.46372)  \n",
       "5    POINT (1.73361 42.54277)  \n",
       "6    POINT (1.53319 42.55623)  \n",
       "7    POINT (1.53414 42.50729)  \n",
       "8    POINT (1.51483 42.54499)  \n",
       "9    POINT (1.52289 42.54391)  \n",
       "10   POINT (1.58014 42.53474)  \n",
       "11    POINT (1.59756 42.5676)  \n",
       "12   POINT (1.48453 42.57205)  \n",
       "13    POINT (1.5251 42.53465)  \n",
       "14   POINT (1.52109 42.50779)  \n",
       "15   POINT (1.50209 42.46245)  \n",
       "16  POINT (55.40708 25.16744)  \n",
       "17  POINT (55.21015 25.15491)  \n",
       "18  POINT (55.55517 25.56473)  \n",
       "19  POINT (55.38947 25.22499)  \n",
       "20   POINT (55.9432 25.78953)  \n",
       "21   POINT (53.7881 23.14355)  \n",
       "22  POINT (56.36256 25.27623)  \n",
       "23  POINT (56.10657 24.81089)  \n",
       "24  POINT (53.70522 23.65416)  \n",
       "25  POINT (56.34199 25.33132)  \n",
       "26   POINT (56.35422 25.0513)  \n",
       "27  POINT (55.24969 25.20795)  \n",
       "28   POINT (55.80772 25.7091)  \n",
       "29  POINT (55.30927 25.07725)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c953382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting HDBSCAN Clustering Process with Admin1 Constraint ---\n",
      "Step 1: Preparing and standardizing data from both sources...\n",
      "  Combined dataset has 263629 unique cities.\n",
      "\n",
      "Step 2: Projecting data and running HDBSCAN clustering...\n",
      "  Parameters: min_cluster_size=5\n",
      "  Starting hdbscan.fit()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HDBSCAN found 7771 clusters and 94908 noise points.\n",
      "\n",
      "Step 3: Identifying representative city for each [cluster, admin1] group...\n",
      "\n",
      "Step 4: Merging cluster results back into the original 'df' DataFrame...\n",
      "\n",
      "--- Process Complete! ---\n",
      "Final dataset contains 215735 cities, enriched with metro area information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "import hdbscan # Import the hdbscan library\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_hdbscan(\n",
    "    gdf_geonames, \n",
    "    df_worldcities,\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies metropolitan areas by clustering cities using HDBSCAN, but constrains\n",
    "    the final \"metro_name\" by administrative boundaries (admin1/state).\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary GeoDataFrame of cities ('df').\n",
    "                                         Must include 'city_name', 'city_latitude',\n",
    "                                         'city_longitude', 'city_population', 'geometry',\n",
    "                                         and 'city_admin1_name'.\n",
    "        df_worldcities (pd.DataFrame): Your secondary DataFrame of major cities ('df2').\n",
    "                                       Must include 'city_ascii', 'lat', 'lng',\n",
    "                                       'population', 'id', and 'admin_name'.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original gdf_geonames with two new columns: 'metro_id' and\n",
    "                          'metro_name', respecting admin1 boundaries.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting HDBSCAN Clustering Process with Admin1 Constraint ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data (Now including admin1 names) ---\n",
    "    print(\"Step 1: Preparing and standardizing data from both sources...\")\n",
    "\n",
    "    # Standardize GeoNames data (your 'df')\n",
    "    gdf_geonames_std = gdf_geonames[['city_name', 'city_latitude', 'city_longitude', 'city_population', 'city_admin1_name', 'geometry']].copy()\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude',\n",
    "        'city_longitude': 'longitude',\n",
    "        'city_population': 'population',\n",
    "        'city_admin1_name': 'admin1_name' # Standardize admin1 column name\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "    \n",
    "    # Standardize and create GeoDataFrame for worldcities (your 'df2')\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name',\n",
    "        'lat': 'latitude',\n",
    "        'lng': 'longitude',\n",
    "        'id': 'original_id',\n",
    "        'admin_name': 'admin1_name' # Standardize admin1 column name\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Combine into a single GeoDataFrame using standardized columns\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'admin1_name', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    \n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    gdf_all_cities['admin1_name'] = gdf_all_cities['admin1_name'].apply(normalize_text) # Normalize admin names for clean grouping\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "    # --- Step 2: Project Data and Run HDBSCAN (Unchanged) ---\n",
    "    print(\"\\nStep 2: Projecting data and running HDBSCAN clustering...\")\n",
    "    print(f\"  Parameters: min_cluster_size={min_cluster_size}\")\n",
    "\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "\n",
    "    print(\"  Starting hdbscan.fit()...\")\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean')\n",
    "    clusterer.fit(coords)\n",
    "        \n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    num_clusters = len(np.unique(clusterer.labels_[clusterer.labels_ != -1]))\n",
    "    num_noise = np.sum(clusterer.labels_ == -1)\n",
    "    print(f\"  HDBSCAN found {num_clusters} clusters and {num_noise} noise points.\")\n",
    "\n",
    "    # --- Step 3: Identify Representative City for Each (Cluster + Admin1) Group ---\n",
    "    print(\"\\nStep 3: Identifying representative city for each [cluster, admin1] group...\")\n",
    "    \n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # ### --- KEY CHANGE --- ###\n",
    "    # Group by BOTH cluster_id AND admin1_name to find the most populous city within each state for each cluster.\n",
    "    idx_of_representatives = gdf_all_cities[gdf_all_cities['cluster_id'] != -1].groupby(['cluster_id', 'admin1_name'])['population'].idxmax()\n",
    "    \n",
    "    representatives = gdf_all_cities.loc[idx_of_representatives].copy()\n",
    "    # ### --- END OF KEY CHANGE --- ###\n",
    "    \n",
    "    # Create a map from [cluster_id, admin1_name] to the representative's name and ID\n",
    "    representatives_map_df = representatives[['cluster_id', 'admin1_name', 'city_name', 'original_id']].copy()\n",
    "    representatives_map_df.rename(columns={'city_name': 'metro_name', 'original_id': 'metro_id'}, inplace=True)\n",
    "    \n",
    "    # --- Step 4: Map Representatives Back Using Both Cluster and Admin1 ---\n",
    "    print(\"\\nStep 4: Merging cluster results back into the original 'df' DataFrame...\")\n",
    "    \n",
    "    # ### --- KEY CHANGE --- ###\n",
    "    # Merge on both cluster_id and admin1_name. This ensures a city in NJ gets the NJ representative.\n",
    "    gdf_all_cities_merged = gdf_all_cities.merge(\n",
    "        representatives_map_df,\n",
    "        on=['cluster_id', 'admin1_name'], \n",
    "        how='left'\n",
    "    )\n",
    "    # ### --- END OF KEY CHANGE --- ###\n",
    "    \n",
    "    # For noise points or cities in a cluster but a different admin1 (now handled by the merge), they represent themselves\n",
    "    is_noise_or_unmatched = gdf_all_cities_merged['metro_name'].isna()\n",
    "    gdf_all_cities_merged.loc[is_noise_or_unmatched, 'metro_name'] = gdf_all_cities_merged.loc[is_noise_or_unmatched, 'city_name']\n",
    "    gdf_all_cities_merged.loc[is_noise_or_unmatched, 'metro_id'] = gdf_all_cities_merged.loc[is_noise_or_unmatched, 'original_id']\n",
    "    \n",
    "    # Filter for the original data source and the columns we need to add back\n",
    "    final_cols_to_merge = gdf_all_cities_merged[gdf_all_cities_merged['source'] == 'geonames'][['original_id', 'metro_id', 'metro_name']]\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    # Merge the new metro columns back to the original gdf_geonames using the index\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    print(f\"Final dataset contains {len(gdf_final)} cities, enriched with metro area information.\")\n",
    "    \n",
    "    return gdf_final\n",
    "final_clustered_gdf2 = cluster_cities_with_hdbscan(\n",
    "    gdf_geonames=df, \n",
    "    df_worldcities=df2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4c74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>metro_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [city_name, city_latitude, city_longitude, city_country_code, city_population, city_admin1_name, city_admin2_name, geometry, metro_id, metro_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"\\nExample: Results for New York City Area\")\n",
    "# Check for a major city name that exists in your df2 data\n",
    "nyc_area = final_clustered_gdf2[final_clustered_gdf2['metro_name'] == 'New York'] \n",
    "nyc_area.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aefa1c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>metro_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>AD</td>\n",
       "      <td>1418</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.56654 42.53176)</td>\n",
       "      <td>1.020417e+09</td>\n",
       "      <td>Encamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>602</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.66769 42.57688)</td>\n",
       "      <td>1.020983e+09</td>\n",
       "      <td>Sant Pere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>AD</td>\n",
       "      <td>833</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51613 42.53368)</td>\n",
       "      <td>1.020543e+09</td>\n",
       "      <td>La Massana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>1052</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "      <td>1.020983e+09</td>\n",
       "      <td>Sant Pere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Sant Juli de Lria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>8022</td>\n",
       "      <td>Sant Juli de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "      <td>1.020886e+09</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>AD</td>\n",
       "      <td>2363</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.73361 42.54277)</td>\n",
       "      <td>1.020417e+09</td>\n",
       "      <td>Encamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>Ordino</td>\n",
       "      <td>42.55623</td>\n",
       "      <td>1.53319</td>\n",
       "      <td>AD</td>\n",
       "      <td>3066</td>\n",
       "      <td>Ordino</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.53319 42.55623)</td>\n",
       "      <td>1.020655e+09</td>\n",
       "      <td>Ordino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>AD</td>\n",
       "      <td>15853</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.53414 42.50729)</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>les Escaldes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>la Massana</td>\n",
       "      <td>42.54499</td>\n",
       "      <td>1.51483</td>\n",
       "      <td>AD</td>\n",
       "      <td>7211</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.51483 42.54499)</td>\n",
       "      <td>1.020543e+09</td>\n",
       "      <td>La Massana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>l'Aldosa</td>\n",
       "      <td>42.54391</td>\n",
       "      <td>1.52289</td>\n",
       "      <td>AD</td>\n",
       "      <td>594</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52289 42.54391)</td>\n",
       "      <td>1.020543e+09</td>\n",
       "      <td>La Massana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>Encamp</td>\n",
       "      <td>42.53474</td>\n",
       "      <td>1.58014</td>\n",
       "      <td>AD</td>\n",
       "      <td>11223</td>\n",
       "      <td>Encamp</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.58014 42.53474)</td>\n",
       "      <td>1.020417e+09</td>\n",
       "      <td>Encamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>Canillo</td>\n",
       "      <td>42.56760</td>\n",
       "      <td>1.59756</td>\n",
       "      <td>AD</td>\n",
       "      <td>3292</td>\n",
       "      <td>Canillo</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.59756 42.5676)</td>\n",
       "      <td>1.020983e+09</td>\n",
       "      <td>Sant Pere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>Arinsal</td>\n",
       "      <td>42.57205</td>\n",
       "      <td>1.48453</td>\n",
       "      <td>AD</td>\n",
       "      <td>1419</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.48453 42.57205)</td>\n",
       "      <td>1.020543e+09</td>\n",
       "      <td>La Massana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>Anys</td>\n",
       "      <td>42.53465</td>\n",
       "      <td>1.52510</td>\n",
       "      <td>AD</td>\n",
       "      <td>1006</td>\n",
       "      <td>La Massana</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.5251 42.53465)</td>\n",
       "      <td>1.020543e+09</td>\n",
       "      <td>La Massana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>AD</td>\n",
       "      <td>20430</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.52109 42.50779)</td>\n",
       "      <td>1.020829e+09</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>Aixirivall</td>\n",
       "      <td>42.46245</td>\n",
       "      <td>1.50209</td>\n",
       "      <td>AD</td>\n",
       "      <td>1041</td>\n",
       "      <td>Sant Juli de Loria</td>\n",
       "      <td></td>\n",
       "      <td>POINT (1.50209 42.46245)</td>\n",
       "      <td>1.020886e+09</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>Warsn</td>\n",
       "      <td>25.16744</td>\n",
       "      <td>55.40708</td>\n",
       "      <td>AE</td>\n",
       "      <td>108759</td>\n",
       "      <td>Dubai</td>\n",
       "      <td></td>\n",
       "      <td>POINT (55.40708 25.16744)</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city_name  city_latitude  city_longitude city_country_code  \\\n",
       "0.0                  Vila       42.53176         1.56654                AD   \n",
       "1.0                Soldeu       42.57688         1.66769                AD   \n",
       "2.0               Sispony       42.53368         1.51613                AD   \n",
       "3.0             El Tarter       42.57952         1.65362                AD   \n",
       "4.0   Sant Juli de Lria       42.46372         1.49129                AD   \n",
       "5.0        Pas de la Casa       42.54277         1.73361                AD   \n",
       "6.0                Ordino       42.55623         1.53319                AD   \n",
       "7.0          les Escaldes       42.50729         1.53414                AD   \n",
       "8.0            la Massana       42.54499         1.51483                AD   \n",
       "9.0              l'Aldosa       42.54391         1.52289                AD   \n",
       "10.0               Encamp       42.53474         1.58014                AD   \n",
       "11.0              Canillo       42.56760         1.59756                AD   \n",
       "12.0              Arinsal       42.57205         1.48453                AD   \n",
       "13.0                Anys       42.53465         1.52510                AD   \n",
       "14.0     Andorra la Vella       42.50779         1.52109                AD   \n",
       "15.0           Aixirivall       42.46245         1.50209                AD   \n",
       "16.0              Warsn       25.16744        55.40708                AE   \n",
       "\n",
       "      city_population     city_admin1_name city_admin2_name  \\\n",
       "0.0              1418               Encamp                    \n",
       "1.0               602              Canillo                    \n",
       "2.0               833           La Massana                    \n",
       "3.0              1052              Canillo                    \n",
       "4.0              8022  Sant Juli de Loria                    \n",
       "5.0              2363               Encamp                    \n",
       "6.0              3066               Ordino                    \n",
       "7.0             15853   Escaldes-Engordany                    \n",
       "8.0              7211           La Massana                    \n",
       "9.0               594           La Massana                    \n",
       "10.0            11223               Encamp                    \n",
       "11.0             3292              Canillo                    \n",
       "12.0             1419           La Massana                    \n",
       "13.0             1006           La Massana                    \n",
       "14.0            20430     Andorra la Vella                    \n",
       "15.0             1041  Sant Juli de Loria                    \n",
       "16.0           108759                Dubai                    \n",
       "\n",
       "                       geometry      metro_id           metro_name  \n",
       "0.0    POINT (1.56654 42.53176)  1.020417e+09               Encamp  \n",
       "1.0    POINT (1.66769 42.57688)  1.020983e+09            Sant Pere  \n",
       "2.0    POINT (1.51613 42.53368)  1.020543e+09           La Massana  \n",
       "3.0    POINT (1.65362 42.57952)  1.020983e+09            Sant Pere  \n",
       "4.0    POINT (1.49129 42.46372)  1.020886e+09  Sant Julia de Loria  \n",
       "5.0    POINT (1.73361 42.54277)  1.020417e+09               Encamp  \n",
       "6.0    POINT (1.53319 42.55623)  1.020655e+09               Ordino  \n",
       "7.0    POINT (1.53414 42.50729)  7.000000e+00         les Escaldes  \n",
       "8.0    POINT (1.51483 42.54499)  1.020543e+09           La Massana  \n",
       "9.0    POINT (1.52289 42.54391)  1.020543e+09           La Massana  \n",
       "10.0   POINT (1.58014 42.53474)  1.020417e+09               Encamp  \n",
       "11.0    POINT (1.59756 42.5676)  1.020983e+09            Sant Pere  \n",
       "12.0   POINT (1.48453 42.57205)  1.020543e+09           La Massana  \n",
       "13.0    POINT (1.5251 42.53465)  1.020543e+09           La Massana  \n",
       "14.0   POINT (1.52109 42.50779)  1.020829e+09     Andorra la Vella  \n",
       "15.0   POINT (1.50209 42.46245)  1.020886e+09  Sant Julia de Loria  \n",
       "16.0  POINT (55.40708 25.16744)  2.900000e+01                Dubai  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clustered_gdf2.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68aacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Two-Tier HDBSCAN Clustering Process ---\n",
      "Step 1: Preparing and standardizing data from both sources...\n",
      "  Combined dataset has 263629 unique cities.\n",
      "\n",
      "Step 2: Running HDBSCAN clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HDBSCAN found 7771 clusters.\n",
      "\n",
      "Step 3: Identifying representatives for both local and greater metro areas...\n",
      "\n",
      "Step 4: Merging two-tier results back into the original 'df' DataFrame...\n",
      "\n",
      "--- Process Complete! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "import hdbscan\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_hdbscan_two_tier(\n",
    "    gdf_geonames, \n",
    "    df_worldcities,\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies both local and greater metropolitan areas using a two-tiered approach.\n",
    "    - Tier 1 (greater_metro_name): Purely spatial clustering to find major metropolitan areas (e.g., \"New York City\").\n",
    "    - Tier 2 (metro_name): Constrained by admin1/admin2 to find local hubs (e.g., \"Brooklyn\", \"Jersey City\").\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary GeoDataFrame ('df'). Requires columns:\n",
    "                                         'city_name', 'city_latitude', 'city_longitude', \n",
    "                                         'city_population', 'city_admin1_name', 'city_admin2_name'.\n",
    "        df_worldcities (pd.DataFrame): Your secondary DataFrame ('df2'). Requires columns:\n",
    "                                       'city_ascii', 'lat', 'lng', 'population', 'id', \n",
    "                                       'admin_name'. 'admin2' data not used from here.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original gdf_geonames with two new columns:\n",
    "                          'metro_name', 'metro_id', 'greater_metro_name', 'greater_metro_id'.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Two-Tier HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data (Now including admin2 names) ---\n",
    "    print(\"Step 1: Preparing and standardizing data from both sources...\")\n",
    "\n",
    "    # Standardize GeoNames data ('df')\n",
    "    cols_needed_geonames = ['city_name', 'city_latitude', 'city_longitude', 'city_population', 'city_admin1_name', 'city_admin2_name', 'geometry']\n",
    "    gdf_geonames_std = gdf_geonames[cols_needed_geonames].copy()\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude', 'city_longitude': 'longitude',\n",
    "        'city_population': 'population', 'city_admin1_name': 'admin1_name',\n",
    "        'city_admin2_name': 'admin2_name'\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "\n",
    "    # Standardize worldcities data ('df2')\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name', 'lat': 'latitude', 'lng': 'longitude',\n",
    "        'id': 'original_id', 'admin_name': 'admin1_name'\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    # Fill admin2 with a placeholder as it's not present in df2\n",
    "    df_worldcities_std['admin2_name'] = pd.NA \n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Combine into a single GeoDataFrame\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'admin1_name', 'admin2_name', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    \n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    \n",
    "    # Normalize text and handle missing admin names for clean grouping\n",
    "    for col in ['admin1_name', 'admin2_name']:\n",
    "        gdf_all_cities[col] = gdf_all_cities[col].apply(normalize_text).fillna('__NONE__')\n",
    "\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "    # --- Step 2: Project Data and Run HDBSCAN (Unchanged) ---\n",
    "    print(\"\\nStep 2: Running HDBSCAN clustering...\")\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean')\n",
    "    clusterer.fit(coords)\n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    print(f\"  HDBSCAN found {len(np.unique(clusterer.labels_)) - 1} clusters.\")\n",
    "\n",
    "    # --- Step 3: Identify Representatives for Both Tiers ---\n",
    "    print(\"\\nStep 3: Identifying representatives for both local and greater metro areas...\")\n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Tier 1: Greater Metro Area (most populous in the whole cluster)\n",
    "    idx_greater = gdf_all_cities.groupby('cluster_id')['population'].idxmax()\n",
    "    reps_greater = gdf_all_cities.loc[idx_greater].copy()\n",
    "    reps_greater = reps_greater[reps_greater['cluster_id'] != -1]\n",
    "    greater_map = reps_greater[['cluster_id', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_name', 'original_id': 'greater_metro_id'}\n",
    "    )\n",
    "\n",
    "    # Tier 2: Local Metro Hub (most populous within cluster/admin1/admin2)\n",
    "    idx_local = gdf_all_cities[gdf_all_cities['cluster_id'] != -1].groupby(['cluster_id', 'admin1_name', 'admin2_name'])['population'].idxmax()\n",
    "    reps_local = gdf_all_cities.loc[idx_local].copy()\n",
    "    local_map = reps_local[['cluster_id', 'admin1_name', 'admin2_name', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'metro_name', 'original_id': 'metro_id'}\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Map Both Tiers Back to the Main DataFrame ---\n",
    "    print(\"\\nStep 4: Merging two-tier results back into the original 'df' DataFrame...\")\n",
    "\n",
    "    # Merge Greater Metro Name (on cluster_id)\n",
    "    gdf_all_merged = gdf_all_cities.merge(greater_map, on='cluster_id', how='left')\n",
    "    \n",
    "    # Merge Local Metro Name (on cluster_id, admin1, admin2)\n",
    "    gdf_all_merged = gdf_all_merged.merge(local_map, on=['cluster_id', 'admin1_name', 'admin2_name'], how='left')\n",
    "\n",
    "    # For noise points or unmatched cities, they represent themselves in both tiers\n",
    "    for tier in ['metro', 'greater_metro']:\n",
    "        is_unmatched = gdf_all_merged[f'{tier}_name'].isna()\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier}_name'] = gdf_all_merged.loc[is_unmatched, 'city_name']\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier}_id'] = gdf_all_merged.loc[is_unmatched, 'original_id']\n",
    "    \n",
    "    # Filter for the original data source and merge back\n",
    "    cols_to_merge = ['original_id', 'metro_name', 'metro_id', 'greater_metro_name', 'greater_metro_id']\n",
    "    final_cols_to_merge = gdf_all_merged[gdf_all_merged['source'] == 'geonames'][cols_to_merge]\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    return gdf_final\n",
    "final_clustered_gdf3 = cluster_cities_with_hdbscan_two_tier(\n",
    "    gdf_geonames=df, \n",
    "    df_worldcities=df2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e553ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Two-Tier HDBSCAN Clustering Process ---\n",
      "Step 1: Preparing and standardizing data...\n",
      "  Combined dataset has 263629 unique cities.\n",
      "\n",
      "Step 2: Running HDBSCAN clustering...\n",
      "  Tuning Parameters: min_cluster_size=5, min_samples=25, epsilon=Nonem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HDBSCAN found 1400 clusters.\n",
      "\n",
      "Step 3: Identifying representatives for both local and greater metro areas...\n",
      "\n",
      "Step 4: Merging two-tier results back into the original 'df' DataFrame...\n",
      "\n",
      "--- Process Complete! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "import hdbscan\n",
    "\n",
    "def normalize_text(text):\n",
    "    # (function remains the same)\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_hdbscan_two_tier_tune(\n",
    "    gdf_geonames, \n",
    "    df_worldcities,\n",
    "    min_cluster_size=15, # Increased default for tighter clusters\n",
    "    min_samples=15,      # Increased default for tighter clusters\n",
    "    cluster_selection_epsilon_meters=None # Optional: hard distance limit\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies metropolitan areas with tunable cluster sizes.\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary city DataFrame ('df').\n",
    "        df_worldcities (pd.DataFrame): Your secondary major city DataFrame ('df2').\n",
    "        min_cluster_size (int): The minimum number of cities required to form a cluster.\n",
    "                                HIGHER values lead to TIGHTER, more urban clusters.\n",
    "        min_samples (int): Controls how conservative clustering is. Higher values make\n",
    "                           clusters denser. Often set to the same as min_cluster_size.\n",
    "                           Set to None to have it default to min_cluster_size.\n",
    "        cluster_selection_epsilon_meters (float, optional): A hard distance limit. No cluster\n",
    "                                                            can span a connection larger than this\n",
    "                                                            distance in meters. e.g., 50000 for 50km.\n",
    "                                                            Defaults to None (no limit).\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Two-Tier HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data (Unchanged) ---\n",
    "    # ... (code for this step is identical to the previous version)\n",
    "    print(\"Step 1: Preparing and standardizing data...\")\n",
    "    cols_needed_geonames = ['city_name', 'city_latitude', 'city_longitude', 'city_population', 'city_admin1_name', 'city_admin2_name', 'geometry']\n",
    "    gdf_geonames_std = gdf_geonames[cols_needed_geonames].copy()\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude', 'city_longitude': 'longitude',\n",
    "        'city_population': 'population', 'city_admin1_name': 'admin1_name',\n",
    "        'city_admin2_name': 'admin2_name'\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name', 'lat': 'latitude', 'lng': 'longitude',\n",
    "        'id': 'original_id', 'admin_name': 'admin1_name'\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    df_worldcities_std['admin2_name'] = pd.NA \n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'admin1_name', 'admin2_name', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    for col in ['admin1_name', 'admin2_name']:\n",
    "        gdf_all_cities[col] = gdf_all_cities[col].apply(normalize_text).fillna('__NONE__')\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "\n",
    "    # --- Step 2: Project Data and Run HDBSCAN with New Parameters ---\n",
    "    print(\"\\nStep 2: Running HDBSCAN clustering...\")\n",
    "    print(f\"  Tuning Parameters: min_cluster_size={min_cluster_size}, min_samples={min_samples}, epsilon={cluster_selection_epsilon_meters}m\")\n",
    "\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "\n",
    "    # ### --- KEY CHANGE --- ###\n",
    "    # Pass the new tuning parameters to the HDBSCAN constructor\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples,\n",
    "        metric='euclidean',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon_meters or 0 # Epsilon must be a number\n",
    "    )\n",
    "    # ### --- END OF KEY CHANGE --- ###\n",
    "\n",
    "    clusterer.fit(coords)\n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    print(f\"  HDBSCAN found {len(np.unique(clusterer.labels_)) - 1} clusters.\")\n",
    "\n",
    "    # --- Step 3 & 4: Identifying and Merging (Unchanged) ---\n",
    "    # ... (code for these steps is identical to the previous version)\n",
    "    print(\"\\nStep 3: Identifying representatives for both local and greater metro areas...\")\n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    idx_greater = gdf_all_cities.groupby('cluster_id')['population'].idxmax()\n",
    "    reps_greater = gdf_all_cities.loc[idx_greater].copy()\n",
    "    reps_greater = reps_greater[reps_greater['cluster_id'] != -1]\n",
    "    greater_map = reps_greater[['cluster_id', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_name', 'original_id': 'greater_metro_id'}\n",
    "    )\n",
    "    idx_local = gdf_all_cities[gdf_all_cities['cluster_id'] != -1].groupby(['cluster_id', 'admin1_name', 'admin2_name'])['population'].idxmax()\n",
    "    reps_local = gdf_all_cities.loc[idx_local].copy()\n",
    "    local_map = reps_local[['cluster_id', 'admin1_name', 'admin2_name', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'metro_name', 'original_id': 'metro_id'}\n",
    "    )\n",
    "    print(\"\\nStep 4: Merging two-tier results back into the original 'df' DataFrame...\")\n",
    "    gdf_all_merged = gdf_all_cities.merge(greater_map, on='cluster_id', how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(local_map, on=['cluster_id', 'admin1_name', 'admin2_name'], how='left')\n",
    "    for tier in ['metro', 'greater_metro']:\n",
    "        is_unmatched = gdf_all_merged[f'{tier}_name'].isna()\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier}_name'] = gdf_all_merged.loc[is_unmatched, 'city_name']\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier}_id'] = gdf_all_merged.loc[is_unmatched, 'original_id']\n",
    "    \n",
    "    cols_to_merge = ['original_id', 'metro_name', 'metro_id', 'greater_metro_name', 'greater_metro_id']\n",
    "    final_cols_to_merge = gdf_all_merged[gdf_all_merged['source'] == 'geonames'][cols_to_merge]\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    return gdf_final\n",
    "\n",
    "final_gdf_tuned = cluster_cities_with_hdbscan_two_tier_tune(\n",
    "    df, \n",
    "    df2,\n",
    "    min_cluster_size=5, # A much higher requirement\n",
    "    min_samples=25       # Keep this matched for now\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustered_gdf3[(final_clustered_gdf3[\"greater_metro_name\"] == \"Phoenix\") & (final_clustered_gdf3[\"city_admin1_name\"] == \"Arizona\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe385479",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gdf_tuned[(final_gdf_tuned[\"metro_name\"] == \"El Paso\") & (final_gdf_tuned[\"city_admin1_name\"] == \"Texas\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54397b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gdf_tuned[(final_gdf_tuned[\"greater_metro_name\"] == \"New York City\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef701de",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustered_gdf3[(final_clustered_gdf3[\"greater_metro_name\"] == \"New York City\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc957a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Three-Tier HDBSCAN Clustering Process ---\n",
      "Step 1: Preparing and standardizing data...\n",
      "  Combined dataset has 263629 unique cities.\n",
      "\n",
      "Step 2: Running HDBSCAN clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\larry\\Desktop\\Geoguessr ML Proj\\Geolocation-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HDBSCAN found 7771 clusters.\n",
      "\n",
      "Step 3: Identifying representatives for all three metro tiers...\n",
      "\n",
      "Step 4: Merging three-tier results back into the original 'df' DataFrame...\n",
      "\n",
      "--- Process Complete! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "import hdbscan\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_hdbscan_three_tier(\n",
    "    gdf_geonames, \n",
    "    df_worldcities,\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None,\n",
    "    cluster_selection_epsilon_meters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies a three-tiered metropolitan hierarchy using HDBSCAN.\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary city DataFrame ('df'). Requires:\n",
    "                                         'city_name', 'city_latitude', 'city_longitude', \n",
    "                                         'city_population', 'city_country_code', 'city_admin1_name', \n",
    "                                         'city_admin2_name'.\n",
    "        df_worldcities (pd.DataFrame): Your secondary major city DataFrame ('df2'). Requires:\n",
    "                                       'city_ascii', 'lat', 'lng', 'population', 'id', \n",
    "                                       'iso2', 'admin_name'.\n",
    "        min_cluster_size, min_samples, cluster_selection_epsilon_meters: Tuning parameters for HDBSCAN.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original gdf_geonames with six new columns representing three tiers of metro areas:\n",
    "                          - metro_name/id: Most granular, respects county/state/country.\n",
    "                          - greater_metro_in_country_name/id: Broad metro area, but respects country borders.\n",
    "                          - greater_metro_name/id: True MSA, can cross all borders.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Three-Tier HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data (Now including country codes) ---\n",
    "    print(\"Step 1: Preparing and standardizing data...\")\n",
    "    \n",
    "    # Standardize GeoNames data ('df')\n",
    "    cols_needed_geonames = ['city_name', 'city_latitude', 'city_longitude', 'city_population', 'city_country_code', 'city_admin1_name', 'city_admin2_name', 'geometry']\n",
    "    gdf_geonames_std = gdf_geonames[cols_needed_geonames].copy()\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude', 'city_longitude': 'longitude',\n",
    "        'city_population': 'population', 'city_country_code': 'country_code',\n",
    "        'city_admin1_name': 'admin1_name', 'city_admin2_name': 'admin2_name'\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "\n",
    "    # Standardize worldcities data ('df2')\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name', 'lat': 'latitude', 'lng': 'longitude',\n",
    "        'id': 'original_id', 'iso2': 'country_code', 'admin_name': 'admin1_name'\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    df_worldcities_std['admin2_name'] = pd.NA\n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Combine into a single GeoDataFrame\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'country_code', 'admin1_name', 'admin2_name', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    \n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    for col in ['admin1_name', 'admin2_name']:\n",
    "        gdf_all_cities[col] = gdf_all_cities[col].apply(normalize_text).fillna('__NONE__')\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "    # --- Step 2: Project Data and Run HDBSCAN (Unchanged) ---\n",
    "    print(\"\\nStep 2: Running HDBSCAN clustering...\")\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon_meters or 0\n",
    "    )\n",
    "    clusterer.fit(coords)\n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    print(f\"  HDBSCAN found {len(np.unique(clusterer.labels_)) - 1} clusters.\")\n",
    "\n",
    "    # --- Step 3: Identify Representatives for All Three Tiers ---\n",
    "    print(\"\\nStep 3: Identifying representatives for all three metro tiers...\")\n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    clustered_cities = gdf_all_cities[gdf_all_cities['cluster_id'] != -1]\n",
    "\n",
    "    # Tier 1: greater_metro (purely spatial)\n",
    "    idx_greater = clustered_cities.groupby('cluster_id')['population'].idxmax()\n",
    "    reps_greater = gdf_all_cities.loc[idx_greater].copy()\n",
    "    greater_map = reps_greater[['cluster_id', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_name', 'original_id': 'greater_metro_id'}\n",
    "    )\n",
    "    \n",
    "    # Tier 2: greater_metro_in_country (spatial, but respects country borders)\n",
    "    idx_greater_country = clustered_cities.groupby(['cluster_id', 'country_code'])['population'].idxmax()\n",
    "    reps_greater_country = gdf_all_cities.loc[idx_greater_country].copy()\n",
    "    greater_country_map = reps_greater_country[['cluster_id', 'country_code', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_in_country_name', 'original_id': 'greater_metro_in_country_id'}\n",
    "    )\n",
    "\n",
    "    # Tier 3: metro (most granular, respects all admin boundaries)\n",
    "    idx_local = clustered_cities.groupby(['cluster_id', 'country_code', 'admin1_name', 'admin2_name'])['population'].idxmax()\n",
    "    reps_local = gdf_all_cities.loc[idx_local].copy()\n",
    "    local_map = reps_local[['cluster_id', 'country_code', 'admin1_name', 'admin2_name', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'metro_name', 'original_id': 'metro_id'}\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Map All Tiers Back to the Main DataFrame ---\n",
    "    print(\"\\nStep 4: Merging three-tier results back into the original 'df' DataFrame...\")\n",
    "\n",
    "    gdf_all_merged = gdf_all_cities.merge(greater_map, on='cluster_id', how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(greater_country_map, on=['cluster_id', 'country_code'], how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(local_map, on=['cluster_id', 'country_code', 'admin1_name', 'admin2_name'], how='left')\n",
    "\n",
    "    # For noise/unmatched points, they represent themselves in all tiers\n",
    "    for tier_prefix in ['metro', 'greater_metro_in_country', 'greater_metro']:\n",
    "        is_unmatched = gdf_all_merged[f'{tier_prefix}_name'].isna()\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier_prefix}_name'] = gdf_all_merged.loc[is_unmatched, 'city_name']\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier_prefix}_id'] = gdf_all_merged.loc[is_unmatched, 'original_id']\n",
    "    \n",
    "    # Filter for the original data source and merge back\n",
    "    cols_to_merge = [\n",
    "        'original_id', 'metro_name', 'metro_id', 'greater_metro_in_country_name', \n",
    "        'greater_metro_in_country_id', 'greater_metro_name', 'greater_metro_id', 'source'\n",
    "    ]\n",
    "    final_cols_to_merge = gdf_all_merged[gdf_all_merged['source'] == 'geonames'][cols_to_merge]\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    return gdf_final\n",
    "\n",
    "final_gdf_tuned = cluster_cities_with_hdbscan_three_tier(\n",
    "    df, \n",
    "    df2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da247b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>greater_metro_in_country_name</th>\n",
       "      <th>greater_metro_in_country_id</th>\n",
       "      <th>greater_metro_name</th>\n",
       "      <th>greater_metro_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137110.0</th>\n",
       "      <td>Praxdis Guerrero</td>\n",
       "      <td>31.36667</td>\n",
       "      <td>-106.01667</td>\n",
       "      <td>MX</td>\n",
       "      <td>3787</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Praxedis G. Guerrero</td>\n",
       "      <td>POINT (-106.01667 31.36667)</td>\n",
       "      <td>Praxdis Guerrero</td>\n",
       "      <td>137166.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137123.0</th>\n",
       "      <td>Jess Carranza (La Colorada)</td>\n",
       "      <td>31.49241</td>\n",
       "      <td>-106.23569</td>\n",
       "      <td>MX</td>\n",
       "      <td>509</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.23569 31.49241)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137133.0</th>\n",
       "      <td>Barreales</td>\n",
       "      <td>31.39806</td>\n",
       "      <td>-106.13917</td>\n",
       "      <td>MX</td>\n",
       "      <td>540</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>POINT (-106.13917 31.39806)</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>139365.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138075.0</th>\n",
       "      <td>San Isidro</td>\n",
       "      <td>31.54666</td>\n",
       "      <td>-106.28124</td>\n",
       "      <td>MX</td>\n",
       "      <td>3483</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.28124 31.54666)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138205.0</th>\n",
       "      <td>San Agustn</td>\n",
       "      <td>31.51674</td>\n",
       "      <td>-106.25548</td>\n",
       "      <td>MX</td>\n",
       "      <td>1359</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.25548 31.51674)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138211.0</th>\n",
       "      <td>Samalayuca</td>\n",
       "      <td>31.34242</td>\n",
       "      <td>-106.47981</td>\n",
       "      <td>MX</td>\n",
       "      <td>1474</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.47981 31.34242)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138347.0</th>\n",
       "      <td>Praxedis G. Guerrero</td>\n",
       "      <td>31.37061</td>\n",
       "      <td>-106.00616</td>\n",
       "      <td>MX</td>\n",
       "      <td>2128</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Praxedis G. Guerrero</td>\n",
       "      <td>POINT (-106.00616 31.37061)</td>\n",
       "      <td>Praxdis Guerrero</td>\n",
       "      <td>137166.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138798.0</th>\n",
       "      <td>Loma Blanca</td>\n",
       "      <td>31.57972</td>\n",
       "      <td>-106.29860</td>\n",
       "      <td>MX</td>\n",
       "      <td>2169</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.2986 31.57972)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138909.0</th>\n",
       "      <td>Rinconada del Mimbre</td>\n",
       "      <td>31.34644</td>\n",
       "      <td>-106.04827</td>\n",
       "      <td>MX</td>\n",
       "      <td>539</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>POINT (-106.04827 31.34644)</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>139365.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139141.0</th>\n",
       "      <td>Jurez y Reforma</td>\n",
       "      <td>31.44000</td>\n",
       "      <td>-106.17056</td>\n",
       "      <td>MX</td>\n",
       "      <td>788</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>POINT (-106.17056 31.44)</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>139365.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139309.0</th>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>31.38950</td>\n",
       "      <td>-106.10574</td>\n",
       "      <td>MX</td>\n",
       "      <td>3022</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>POINT (-106.10574 31.3895)</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>139365.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139397.0</th>\n",
       "      <td>Esperanza</td>\n",
       "      <td>31.33051</td>\n",
       "      <td>-105.96176</td>\n",
       "      <td>MX</td>\n",
       "      <td>710</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Praxedis G. Guerrero</td>\n",
       "      <td>POINT (-105.96176 31.33051)</td>\n",
       "      <td>Praxdis Guerrero</td>\n",
       "      <td>137166.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139525.0</th>\n",
       "      <td>Porvenir</td>\n",
       "      <td>31.24038</td>\n",
       "      <td>-105.87664</td>\n",
       "      <td>MX</td>\n",
       "      <td>1253</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Praxedis G. Guerrero</td>\n",
       "      <td>POINT (-105.87664 31.24038)</td>\n",
       "      <td>Praxdis Guerrero</td>\n",
       "      <td>137166.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139557.0</th>\n",
       "      <td>Tres Jacales</td>\n",
       "      <td>31.45850</td>\n",
       "      <td>-106.20128</td>\n",
       "      <td>MX</td>\n",
       "      <td>727</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.20128 31.4585)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139889.0</th>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>31.72024</td>\n",
       "      <td>-106.46084</td>\n",
       "      <td>MX</td>\n",
       "      <td>1501551</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>Jurez</td>\n",
       "      <td>POINT (-106.46084 31.72024)</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>1.399450e+05</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209547.0</th>\n",
       "      <td>Anthony</td>\n",
       "      <td>32.00399</td>\n",
       "      <td>-106.60583</td>\n",
       "      <td>US</td>\n",
       "      <td>9293</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.60583 32.00399)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209555.0</th>\n",
       "      <td>Berino</td>\n",
       "      <td>32.07093</td>\n",
       "      <td>-106.62138</td>\n",
       "      <td>US</td>\n",
       "      <td>1441</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.62138 32.07093)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209569.0</th>\n",
       "      <td>Chamberino</td>\n",
       "      <td>32.04010</td>\n",
       "      <td>-106.68555</td>\n",
       "      <td>US</td>\n",
       "      <td>919</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.68555 32.0401)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209571.0</th>\n",
       "      <td>Chaparral</td>\n",
       "      <td>32.02376</td>\n",
       "      <td>-106.38566</td>\n",
       "      <td>US</td>\n",
       "      <td>14631</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.38566 32.02376)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209587.0</th>\n",
       "      <td>Doa Ana</td>\n",
       "      <td>32.38954</td>\n",
       "      <td>-106.81390</td>\n",
       "      <td>US</td>\n",
       "      <td>1211</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.8139 32.38954)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209601.0</th>\n",
       "      <td>Fairacres</td>\n",
       "      <td>32.30398</td>\n",
       "      <td>-106.84667</td>\n",
       "      <td>US</td>\n",
       "      <td>824</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.84667 32.30398)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209608.0</th>\n",
       "      <td>Hatch</td>\n",
       "      <td>32.66536</td>\n",
       "      <td>-107.15307</td>\n",
       "      <td>US</td>\n",
       "      <td>1600</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-107.15307 32.66536)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209620.0</th>\n",
       "      <td>La Mesa</td>\n",
       "      <td>32.12204</td>\n",
       "      <td>-106.70778</td>\n",
       "      <td>US</td>\n",
       "      <td>728</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.70778 32.12204)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209624.0</th>\n",
       "      <td>La Union</td>\n",
       "      <td>31.95066</td>\n",
       "      <td>-106.66166</td>\n",
       "      <td>US</td>\n",
       "      <td>1106</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.66166 31.95066)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209627.0</th>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>32.31232</td>\n",
       "      <td>-106.77834</td>\n",
       "      <td>US</td>\n",
       "      <td>101643</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.77834 32.31232)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209646.0</th>\n",
       "      <td>Mesilla</td>\n",
       "      <td>32.27009</td>\n",
       "      <td>-106.80084</td>\n",
       "      <td>US</td>\n",
       "      <td>1874</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.80084 32.27009)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209648.0</th>\n",
       "      <td>Mesquite</td>\n",
       "      <td>32.16454</td>\n",
       "      <td>-106.69666</td>\n",
       "      <td>US</td>\n",
       "      <td>1112</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.69666 32.16454)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209672.0</th>\n",
       "      <td>Radium Springs</td>\n",
       "      <td>32.50120</td>\n",
       "      <td>-106.92807</td>\n",
       "      <td>US</td>\n",
       "      <td>1699</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.92807 32.5012)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209681.0</th>\n",
       "      <td>Salem</td>\n",
       "      <td>32.70758</td>\n",
       "      <td>-107.21308</td>\n",
       "      <td>US</td>\n",
       "      <td>942</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-107.21308 32.70758)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209687.0</th>\n",
       "      <td>San Miguel</td>\n",
       "      <td>32.15538</td>\n",
       "      <td>-106.73500</td>\n",
       "      <td>US</td>\n",
       "      <td>1153</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.735 32.15538)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209688.0</th>\n",
       "      <td>San Pablo</td>\n",
       "      <td>32.24954</td>\n",
       "      <td>-106.77278</td>\n",
       "      <td>US</td>\n",
       "      <td>806</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.77278 32.24954)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209690.0</th>\n",
       "      <td>San Ysidro</td>\n",
       "      <td>32.35093</td>\n",
       "      <td>-106.81112</td>\n",
       "      <td>US</td>\n",
       "      <td>2090</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.81112 32.35093)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209699.0</th>\n",
       "      <td>Santa Teresa</td>\n",
       "      <td>31.85594</td>\n",
       "      <td>-106.63916</td>\n",
       "      <td>US</td>\n",
       "      <td>4258</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.63916 31.85594)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209708.0</th>\n",
       "      <td>Sunland Park</td>\n",
       "      <td>31.79650</td>\n",
       "      <td>-106.57999</td>\n",
       "      <td>US</td>\n",
       "      <td>15940</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.57999 31.7965)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209726.0</th>\n",
       "      <td>University Park</td>\n",
       "      <td>32.28343</td>\n",
       "      <td>-106.75334</td>\n",
       "      <td>US</td>\n",
       "      <td>4192</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.75334 32.28343)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209728.0</th>\n",
       "      <td>Vado</td>\n",
       "      <td>32.11176</td>\n",
       "      <td>-106.66250</td>\n",
       "      <td>US</td>\n",
       "      <td>3194</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.6625 32.11176)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209733.0</th>\n",
       "      <td>White Sands</td>\n",
       "      <td>32.38093</td>\n",
       "      <td>-106.47944</td>\n",
       "      <td>US</td>\n",
       "      <td>1651</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-106.47944 32.38093)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209804.0</th>\n",
       "      <td>Agua Dulce</td>\n",
       "      <td>31.65511</td>\n",
       "      <td>-106.13887</td>\n",
       "      <td>US</td>\n",
       "      <td>3014</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.13887 31.65511)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209809.0</th>\n",
       "      <td>Anthony</td>\n",
       "      <td>31.99927</td>\n",
       "      <td>-106.60555</td>\n",
       "      <td>US</td>\n",
       "      <td>5517</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.60555 31.99927)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209824.0</th>\n",
       "      <td>Canutillo</td>\n",
       "      <td>31.91149</td>\n",
       "      <td>-106.60027</td>\n",
       "      <td>US</td>\n",
       "      <td>6321</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.60027 31.91149)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209833.0</th>\n",
       "      <td>Clint</td>\n",
       "      <td>31.59234</td>\n",
       "      <td>-106.22414</td>\n",
       "      <td>US</td>\n",
       "      <td>1146</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.22414 31.59234)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209847.0</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>31.75872</td>\n",
       "      <td>-106.48693</td>\n",
       "      <td>US</td>\n",
       "      <td>681124</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.48693 31.75872)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209850.0</th>\n",
       "      <td>Fabens</td>\n",
       "      <td>31.50234</td>\n",
       "      <td>-106.15859</td>\n",
       "      <td>US</td>\n",
       "      <td>8257</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.15859 31.50234)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209855.0</th>\n",
       "      <td>Fort Hancock</td>\n",
       "      <td>31.29846</td>\n",
       "      <td>-105.84525</td>\n",
       "      <td>US</td>\n",
       "      <td>1750</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Hudspeth County</td>\n",
       "      <td>POINT (-105.84525 31.29846)</td>\n",
       "      <td>Fort Hancock</td>\n",
       "      <td>210005.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209871.0</th>\n",
       "      <td>Homestead Meadows North</td>\n",
       "      <td>31.84963</td>\n",
       "      <td>-106.17285</td>\n",
       "      <td>US</td>\n",
       "      <td>5124</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.17285 31.84963)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209872.0</th>\n",
       "      <td>Homestead Meadows South</td>\n",
       "      <td>31.81097</td>\n",
       "      <td>-106.16427</td>\n",
       "      <td>US</td>\n",
       "      <td>7247</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.16427 31.81097)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209873.0</th>\n",
       "      <td>Horizon City</td>\n",
       "      <td>31.69261</td>\n",
       "      <td>-106.20748</td>\n",
       "      <td>US</td>\n",
       "      <td>19288</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.20748 31.69261)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209904.0</th>\n",
       "      <td>Morning Glory</td>\n",
       "      <td>31.57012</td>\n",
       "      <td>-106.21581</td>\n",
       "      <td>US</td>\n",
       "      <td>651</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.21581 31.57012)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209932.0</th>\n",
       "      <td>San Elizario</td>\n",
       "      <td>31.58511</td>\n",
       "      <td>-106.27276</td>\n",
       "      <td>US</td>\n",
       "      <td>8999</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.27276 31.58511)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209945.0</th>\n",
       "      <td>Socorro</td>\n",
       "      <td>31.65456</td>\n",
       "      <td>-106.30331</td>\n",
       "      <td>US</td>\n",
       "      <td>33222</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.30331 31.65456)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209946.0</th>\n",
       "      <td>Socorro Mission Number 1 Colonia</td>\n",
       "      <td>31.63622</td>\n",
       "      <td>-106.29054</td>\n",
       "      <td>US</td>\n",
       "      <td>28637</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.29054 31.63622)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209948.0</th>\n",
       "      <td>Sparks</td>\n",
       "      <td>31.67261</td>\n",
       "      <td>-106.23970</td>\n",
       "      <td>US</td>\n",
       "      <td>4529</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.2397 31.67261)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209961.0</th>\n",
       "      <td>Tornillo</td>\n",
       "      <td>31.44540</td>\n",
       "      <td>-106.08831</td>\n",
       "      <td>US</td>\n",
       "      <td>1568</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.08831 31.4454)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209966.0</th>\n",
       "      <td>Vinton</td>\n",
       "      <td>31.95121</td>\n",
       "      <td>-106.60249</td>\n",
       "      <td>US</td>\n",
       "      <td>1973</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.60249 31.95121)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209969.0</th>\n",
       "      <td>Westway</td>\n",
       "      <td>31.95871</td>\n",
       "      <td>-106.57805</td>\n",
       "      <td>US</td>\n",
       "      <td>4188</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.57805 31.95871)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210058.0</th>\n",
       "      <td>Placitas</td>\n",
       "      <td>32.66508</td>\n",
       "      <td>-107.16863</td>\n",
       "      <td>US</td>\n",
       "      <td>576</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Doa Ana County</td>\n",
       "      <td>POINT (-107.16863 32.66508)</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>209777.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212120.0</th>\n",
       "      <td>Fort Bliss</td>\n",
       "      <td>31.81357</td>\n",
       "      <td>-106.41224</td>\n",
       "      <td>US</td>\n",
       "      <td>8591</td>\n",
       "      <td>Texas</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>POINT (-106.41224 31.81357)</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>209997.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>1.840023e+09</td>\n",
       "      <td>Ciudad Jurez</td>\n",
       "      <td>139945.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 city_name  city_latitude  city_longitude  \\\n",
       "137110.0                 Praxdis Guerrero       31.36667      -106.01667   \n",
       "137123.0      Jess Carranza (La Colorada)       31.49241      -106.23569   \n",
       "137133.0                         Barreales       31.39806      -106.13917   \n",
       "138075.0                        San Isidro       31.54666      -106.28124   \n",
       "138205.0                       San Agustn       31.51674      -106.25548   \n",
       "138211.0                        Samalayuca       31.34242      -106.47981   \n",
       "138347.0              Praxedis G. Guerrero       31.37061      -106.00616   \n",
       "138798.0                       Loma Blanca       31.57972      -106.29860   \n",
       "138909.0              Rinconada del Mimbre       31.34644      -106.04827   \n",
       "139141.0                  Jurez y Reforma       31.44000      -106.17056   \n",
       "139309.0                         Guadalupe       31.38950      -106.10574   \n",
       "139397.0                         Esperanza       31.33051      -105.96176   \n",
       "139525.0                          Porvenir       31.24038      -105.87664   \n",
       "139557.0                      Tres Jacales       31.45850      -106.20128   \n",
       "139889.0                     Ciudad Jurez       31.72024      -106.46084   \n",
       "209547.0                           Anthony       32.00399      -106.60583   \n",
       "209555.0                            Berino       32.07093      -106.62138   \n",
       "209569.0                        Chamberino       32.04010      -106.68555   \n",
       "209571.0                         Chaparral       32.02376      -106.38566   \n",
       "209587.0                          Doa Ana       32.38954      -106.81390   \n",
       "209601.0                         Fairacres       32.30398      -106.84667   \n",
       "209608.0                             Hatch       32.66536      -107.15307   \n",
       "209620.0                           La Mesa       32.12204      -106.70778   \n",
       "209624.0                          La Union       31.95066      -106.66166   \n",
       "209627.0                        Las Cruces       32.31232      -106.77834   \n",
       "209646.0                           Mesilla       32.27009      -106.80084   \n",
       "209648.0                          Mesquite       32.16454      -106.69666   \n",
       "209672.0                    Radium Springs       32.50120      -106.92807   \n",
       "209681.0                             Salem       32.70758      -107.21308   \n",
       "209687.0                        San Miguel       32.15538      -106.73500   \n",
       "209688.0                         San Pablo       32.24954      -106.77278   \n",
       "209690.0                        San Ysidro       32.35093      -106.81112   \n",
       "209699.0                      Santa Teresa       31.85594      -106.63916   \n",
       "209708.0                      Sunland Park       31.79650      -106.57999   \n",
       "209726.0                   University Park       32.28343      -106.75334   \n",
       "209728.0                              Vado       32.11176      -106.66250   \n",
       "209733.0                       White Sands       32.38093      -106.47944   \n",
       "209804.0                        Agua Dulce       31.65511      -106.13887   \n",
       "209809.0                           Anthony       31.99927      -106.60555   \n",
       "209824.0                         Canutillo       31.91149      -106.60027   \n",
       "209833.0                             Clint       31.59234      -106.22414   \n",
       "209847.0                           El Paso       31.75872      -106.48693   \n",
       "209850.0                            Fabens       31.50234      -106.15859   \n",
       "209855.0                      Fort Hancock       31.29846      -105.84525   \n",
       "209871.0           Homestead Meadows North       31.84963      -106.17285   \n",
       "209872.0           Homestead Meadows South       31.81097      -106.16427   \n",
       "209873.0                      Horizon City       31.69261      -106.20748   \n",
       "209904.0                     Morning Glory       31.57012      -106.21581   \n",
       "209932.0                      San Elizario       31.58511      -106.27276   \n",
       "209945.0                           Socorro       31.65456      -106.30331   \n",
       "209946.0  Socorro Mission Number 1 Colonia       31.63622      -106.29054   \n",
       "209948.0                            Sparks       31.67261      -106.23970   \n",
       "209961.0                          Tornillo       31.44540      -106.08831   \n",
       "209966.0                            Vinton       31.95121      -106.60249   \n",
       "209969.0                           Westway       31.95871      -106.57805   \n",
       "210058.0                          Placitas       32.66508      -107.16863   \n",
       "212120.0                        Fort Bliss       31.81357      -106.41224   \n",
       "\n",
       "         city_country_code  city_population city_admin1_name  \\\n",
       "137110.0                MX             3787        Chihuahua   \n",
       "137123.0                MX              509        Chihuahua   \n",
       "137133.0                MX              540        Chihuahua   \n",
       "138075.0                MX             3483        Chihuahua   \n",
       "138205.0                MX             1359        Chihuahua   \n",
       "138211.0                MX             1474        Chihuahua   \n",
       "138347.0                MX             2128        Chihuahua   \n",
       "138798.0                MX             2169        Chihuahua   \n",
       "138909.0                MX              539        Chihuahua   \n",
       "139141.0                MX              788        Chihuahua   \n",
       "139309.0                MX             3022        Chihuahua   \n",
       "139397.0                MX              710        Chihuahua   \n",
       "139525.0                MX             1253        Chihuahua   \n",
       "139557.0                MX              727        Chihuahua   \n",
       "139889.0                MX          1501551        Chihuahua   \n",
       "209547.0                US             9293       New Mexico   \n",
       "209555.0                US             1441       New Mexico   \n",
       "209569.0                US              919       New Mexico   \n",
       "209571.0                US            14631       New Mexico   \n",
       "209587.0                US             1211       New Mexico   \n",
       "209601.0                US              824       New Mexico   \n",
       "209608.0                US             1600       New Mexico   \n",
       "209620.0                US              728       New Mexico   \n",
       "209624.0                US             1106       New Mexico   \n",
       "209627.0                US           101643       New Mexico   \n",
       "209646.0                US             1874       New Mexico   \n",
       "209648.0                US             1112       New Mexico   \n",
       "209672.0                US             1699       New Mexico   \n",
       "209681.0                US              942       New Mexico   \n",
       "209687.0                US             1153       New Mexico   \n",
       "209688.0                US              806       New Mexico   \n",
       "209690.0                US             2090       New Mexico   \n",
       "209699.0                US             4258       New Mexico   \n",
       "209708.0                US            15940       New Mexico   \n",
       "209726.0                US             4192       New Mexico   \n",
       "209728.0                US             3194       New Mexico   \n",
       "209733.0                US             1651       New Mexico   \n",
       "209804.0                US             3014            Texas   \n",
       "209809.0                US             5517            Texas   \n",
       "209824.0                US             6321            Texas   \n",
       "209833.0                US             1146            Texas   \n",
       "209847.0                US           681124            Texas   \n",
       "209850.0                US             8257            Texas   \n",
       "209855.0                US             1750            Texas   \n",
       "209871.0                US             5124            Texas   \n",
       "209872.0                US             7247            Texas   \n",
       "209873.0                US            19288            Texas   \n",
       "209904.0                US              651            Texas   \n",
       "209932.0                US             8999            Texas   \n",
       "209945.0                US            33222            Texas   \n",
       "209946.0                US            28637            Texas   \n",
       "209948.0                US             4529            Texas   \n",
       "209961.0                US             1568            Texas   \n",
       "209966.0                US             1973            Texas   \n",
       "209969.0                US             4188            Texas   \n",
       "210058.0                US              576       New Mexico   \n",
       "212120.0                US             8591            Texas   \n",
       "\n",
       "              city_admin2_name                     geometry  \\\n",
       "137110.0  Praxedis G. Guerrero  POINT (-106.01667 31.36667)   \n",
       "137123.0                Jurez  POINT (-106.23569 31.49241)   \n",
       "137133.0             Guadalupe  POINT (-106.13917 31.39806)   \n",
       "138075.0                Jurez  POINT (-106.28124 31.54666)   \n",
       "138205.0                Jurez  POINT (-106.25548 31.51674)   \n",
       "138211.0                Jurez  POINT (-106.47981 31.34242)   \n",
       "138347.0  Praxedis G. Guerrero  POINT (-106.00616 31.37061)   \n",
       "138798.0                Jurez   POINT (-106.2986 31.57972)   \n",
       "138909.0             Guadalupe  POINT (-106.04827 31.34644)   \n",
       "139141.0             Guadalupe     POINT (-106.17056 31.44)   \n",
       "139309.0             Guadalupe   POINT (-106.10574 31.3895)   \n",
       "139397.0  Praxedis G. Guerrero  POINT (-105.96176 31.33051)   \n",
       "139525.0  Praxedis G. Guerrero  POINT (-105.87664 31.24038)   \n",
       "139557.0                Jurez   POINT (-106.20128 31.4585)   \n",
       "139889.0                Jurez  POINT (-106.46084 31.72024)   \n",
       "209547.0       Doa Ana County  POINT (-106.60583 32.00399)   \n",
       "209555.0       Doa Ana County  POINT (-106.62138 32.07093)   \n",
       "209569.0       Doa Ana County   POINT (-106.68555 32.0401)   \n",
       "209571.0       Doa Ana County  POINT (-106.38566 32.02376)   \n",
       "209587.0       Doa Ana County   POINT (-106.8139 32.38954)   \n",
       "209601.0       Doa Ana County  POINT (-106.84667 32.30398)   \n",
       "209608.0       Doa Ana County  POINT (-107.15307 32.66536)   \n",
       "209620.0       Doa Ana County  POINT (-106.70778 32.12204)   \n",
       "209624.0       Doa Ana County  POINT (-106.66166 31.95066)   \n",
       "209627.0       Doa Ana County  POINT (-106.77834 32.31232)   \n",
       "209646.0       Doa Ana County  POINT (-106.80084 32.27009)   \n",
       "209648.0       Doa Ana County  POINT (-106.69666 32.16454)   \n",
       "209672.0       Doa Ana County   POINT (-106.92807 32.5012)   \n",
       "209681.0       Doa Ana County  POINT (-107.21308 32.70758)   \n",
       "209687.0       Doa Ana County    POINT (-106.735 32.15538)   \n",
       "209688.0       Doa Ana County  POINT (-106.77278 32.24954)   \n",
       "209690.0       Doa Ana County  POINT (-106.81112 32.35093)   \n",
       "209699.0       Doa Ana County  POINT (-106.63916 31.85594)   \n",
       "209708.0       Doa Ana County   POINT (-106.57999 31.7965)   \n",
       "209726.0       Doa Ana County  POINT (-106.75334 32.28343)   \n",
       "209728.0       Doa Ana County   POINT (-106.6625 32.11176)   \n",
       "209733.0       Doa Ana County  POINT (-106.47944 32.38093)   \n",
       "209804.0        El Paso County  POINT (-106.13887 31.65511)   \n",
       "209809.0        El Paso County  POINT (-106.60555 31.99927)   \n",
       "209824.0        El Paso County  POINT (-106.60027 31.91149)   \n",
       "209833.0        El Paso County  POINT (-106.22414 31.59234)   \n",
       "209847.0        El Paso County  POINT (-106.48693 31.75872)   \n",
       "209850.0        El Paso County  POINT (-106.15859 31.50234)   \n",
       "209855.0       Hudspeth County  POINT (-105.84525 31.29846)   \n",
       "209871.0        El Paso County  POINT (-106.17285 31.84963)   \n",
       "209872.0        El Paso County  POINT (-106.16427 31.81097)   \n",
       "209873.0        El Paso County  POINT (-106.20748 31.69261)   \n",
       "209904.0        El Paso County  POINT (-106.21581 31.57012)   \n",
       "209932.0        El Paso County  POINT (-106.27276 31.58511)   \n",
       "209945.0        El Paso County  POINT (-106.30331 31.65456)   \n",
       "209946.0        El Paso County  POINT (-106.29054 31.63622)   \n",
       "209948.0        El Paso County   POINT (-106.2397 31.67261)   \n",
       "209961.0        El Paso County   POINT (-106.08831 31.4454)   \n",
       "209966.0        El Paso County  POINT (-106.60249 31.95121)   \n",
       "209969.0        El Paso County  POINT (-106.57805 31.95871)   \n",
       "210058.0       Doa Ana County  POINT (-107.16863 32.66508)   \n",
       "212120.0        El Paso County  POINT (-106.41224 31.81357)   \n",
       "\n",
       "                 metro_name  metro_id greater_metro_in_country_name  \\\n",
       "137110.0  Praxdis Guerrero  137166.0                 Ciudad Jurez   \n",
       "137123.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "137133.0          Guadalupe  139365.0                 Ciudad Jurez   \n",
       "138075.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "138205.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "138211.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "138347.0  Praxdis Guerrero  137166.0                 Ciudad Jurez   \n",
       "138798.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "138909.0          Guadalupe  139365.0                 Ciudad Jurez   \n",
       "139141.0          Guadalupe  139365.0                 Ciudad Jurez   \n",
       "139309.0          Guadalupe  139365.0                 Ciudad Jurez   \n",
       "139397.0  Praxdis Guerrero  137166.0                 Ciudad Jurez   \n",
       "139525.0  Praxdis Guerrero  137166.0                 Ciudad Jurez   \n",
       "139557.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "139889.0      Ciudad Jurez  139945.0                 Ciudad Jurez   \n",
       "209547.0         Las Cruces  209777.0                       El Paso   \n",
       "209555.0         Las Cruces  209777.0                       El Paso   \n",
       "209569.0         Las Cruces  209777.0                       El Paso   \n",
       "209571.0         Las Cruces  209777.0                       El Paso   \n",
       "209587.0         Las Cruces  209777.0                       El Paso   \n",
       "209601.0         Las Cruces  209777.0                       El Paso   \n",
       "209608.0         Las Cruces  209777.0                       El Paso   \n",
       "209620.0         Las Cruces  209777.0                       El Paso   \n",
       "209624.0         Las Cruces  209777.0                       El Paso   \n",
       "209627.0         Las Cruces  209777.0                       El Paso   \n",
       "209646.0         Las Cruces  209777.0                       El Paso   \n",
       "209648.0         Las Cruces  209777.0                       El Paso   \n",
       "209672.0         Las Cruces  209777.0                       El Paso   \n",
       "209681.0         Las Cruces  209777.0                       El Paso   \n",
       "209687.0         Las Cruces  209777.0                       El Paso   \n",
       "209688.0         Las Cruces  209777.0                       El Paso   \n",
       "209690.0         Las Cruces  209777.0                       El Paso   \n",
       "209699.0         Las Cruces  209777.0                       El Paso   \n",
       "209708.0         Las Cruces  209777.0                       El Paso   \n",
       "209726.0         Las Cruces  209777.0                       El Paso   \n",
       "209728.0         Las Cruces  209777.0                       El Paso   \n",
       "209733.0         Las Cruces  209777.0                       El Paso   \n",
       "209804.0            El Paso  209997.0                       El Paso   \n",
       "209809.0            El Paso  209997.0                       El Paso   \n",
       "209824.0            El Paso  209997.0                       El Paso   \n",
       "209833.0            El Paso  209997.0                       El Paso   \n",
       "209847.0            El Paso  209997.0                       El Paso   \n",
       "209850.0            El Paso  209997.0                       El Paso   \n",
       "209855.0       Fort Hancock  210005.0                       El Paso   \n",
       "209871.0            El Paso  209997.0                       El Paso   \n",
       "209872.0            El Paso  209997.0                       El Paso   \n",
       "209873.0            El Paso  209997.0                       El Paso   \n",
       "209904.0            El Paso  209997.0                       El Paso   \n",
       "209932.0            El Paso  209997.0                       El Paso   \n",
       "209945.0            El Paso  209997.0                       El Paso   \n",
       "209946.0            El Paso  209997.0                       El Paso   \n",
       "209948.0            El Paso  209997.0                       El Paso   \n",
       "209961.0            El Paso  209997.0                       El Paso   \n",
       "209966.0            El Paso  209997.0                       El Paso   \n",
       "209969.0            El Paso  209997.0                       El Paso   \n",
       "210058.0         Las Cruces  209777.0                       El Paso   \n",
       "212120.0            El Paso  209997.0                       El Paso   \n",
       "\n",
       "          greater_metro_in_country_id greater_metro_name  greater_metro_id  \n",
       "137110.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "137123.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "137133.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "138075.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "138205.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "138211.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "138347.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "138798.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "138909.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "139141.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "139309.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "139397.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "139525.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "139557.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "139889.0                 1.399450e+05      Ciudad Jurez          139945.0  \n",
       "209547.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209555.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209569.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209571.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209587.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209601.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209608.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209620.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209624.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209627.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209646.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209648.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209672.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209681.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209687.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209688.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209690.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209699.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209708.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209726.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209728.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209733.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209804.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209809.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209824.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209833.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209847.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209850.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209855.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209871.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209872.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209873.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209904.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209932.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209945.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209946.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209948.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209961.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209966.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "209969.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "210058.0                 1.840023e+09      Ciudad Jurez          139945.0  \n",
       "212120.0                 1.840023e+09      Ciudad Jurez          139945.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gdf_tuned[(final_gdf_tuned[\"greater_metro_name\"] == \"Ciudad Jurez\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa8e4f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>city_country_code</th>\n",
       "      <th>city_population</th>\n",
       "      <th>city_admin1_name</th>\n",
       "      <th>city_admin2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>greater_metro_in_country_name</th>\n",
       "      <th>greater_metro_in_country_id</th>\n",
       "      <th>greater_metro_name</th>\n",
       "      <th>greater_metro_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115567.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.93645</td>\n",
       "      <td>7.54015</td>\n",
       "      <td>IT</td>\n",
       "      <td>7507</td>\n",
       "      <td>Piedmont</td>\n",
       "      <td>Torino</td>\n",
       "      <td>POINT (7.54015 44.93645)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115608.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115608.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115608.0</td>\n",
       "      <td>geonames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city_name  city_latitude  city_longitude city_country_code  \\\n",
       "115567.0       NaN       44.93645         7.54015                IT   \n",
       "\n",
       "          city_population city_admin1_name city_admin2_name  \\\n",
       "115567.0             7507         Piedmont           Torino   \n",
       "\n",
       "                          geometry metro_name  metro_id  \\\n",
       "115567.0  POINT (7.54015 44.93645)        NaN  115608.0   \n",
       "\n",
       "         greater_metro_in_country_name  greater_metro_in_country_id  \\\n",
       "115567.0                           NaN                     115608.0   \n",
       "\n",
       "         greater_metro_name  greater_metro_id    source  \n",
       "115567.0                NaN          115608.0  geonames  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gdf_tuned[final_gdf_tuned[\"city_name\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ae252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from unidecode import unidecode\n",
    "import hdbscan\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Converts a string to its closest ASCII representation.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unidecode(text)\n",
    "    return text\n",
    "\n",
    "def cluster_cities_with_hdbscan_three_tier(\n",
    "    gdf_geonames, \n",
    "    df_worldcities,\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None,\n",
    "    cluster_selection_epsilon_meters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies a three-tiered metropolitan hierarchy using HDBSCAN.\n",
    "\n",
    "    Args:\n",
    "        gdf_geonames (gpd.GeoDataFrame): Your primary city DataFrame ('df'). Requires:\n",
    "                                         'city_name', 'city_latitude', 'city_longitude', \n",
    "                                         'city_population', 'city_country_code', 'city_admin1_name', \n",
    "                                         'city_admin2_name'.\n",
    "        df_worldcities (pd.DataFrame): Your secondary major city DataFrame ('df2'). Requires:\n",
    "                                       'city_ascii', 'lat', 'lng', 'population', 'id', \n",
    "                                       'iso2', 'admin_name'.\n",
    "        min_cluster_size, min_samples, cluster_selection_epsilon_meters: Tuning parameters for HDBSCAN.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original gdf_geonames with six new columns representing three tiers of metro areas:\n",
    "                          - metro_name/id: Most granular, respects county/state/country.\n",
    "                          - greater_metro_in_country_name/id: Broad metro area, but respects country borders.\n",
    "                          - greater_metro_name/id: True MSA, can cross all borders.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Three-Tier HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare and Combine Data (Now including country codes) ---\n",
    "    print(\"Step 1: Preparing and standardizing data...\")\n",
    "    \n",
    "    # Standardize GeoNames data ('df')\n",
    "    cols_needed_geonames = ['city_name', 'city_latitude', 'city_longitude', 'city_population', 'city_country_code', 'city_admin1_name', 'city_admin2_name', 'geometry']\n",
    "    gdf_geonames_std = gdf_geonames[cols_needed_geonames].copy()\n",
    "    gdf_geonames_std['original_id'] = gdf_geonames.index\n",
    "    gdf_geonames_std.rename(columns={\n",
    "        'city_latitude': 'latitude', 'city_longitude': 'longitude',\n",
    "        'city_population': 'population', 'city_country_code': 'country_code',\n",
    "        'city_admin1_name': 'admin1_name', 'city_admin2_name': 'admin2_name'\n",
    "    }, inplace=True)\n",
    "    gdf_geonames_std['source'] = 'geonames'\n",
    "\n",
    "    # Standardize worldcities data ('df2')\n",
    "    df_worldcities_std = df_worldcities.copy()\n",
    "    df_worldcities_std.rename(columns={\n",
    "        'city_ascii': 'city_name', 'lat': 'latitude', 'lng': 'longitude',\n",
    "        'id': 'original_id', 'iso2': 'country_code', 'admin_name': 'admin1_name'\n",
    "    }, inplace=True)\n",
    "    df_worldcities_std['source'] = 'worldcities'\n",
    "    df_worldcities_std['admin2_name'] = pd.NA\n",
    "    \n",
    "    gdf_worldcities_std = gpd.GeoDataFrame(\n",
    "        df_worldcities_std,\n",
    "        geometry=gpd.points_from_xy(df_worldcities_std.longitude, df_worldcities_std.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Combine into a single GeoDataFrame\n",
    "    cols_to_combine = ['original_id', 'city_name', 'latitude', 'longitude', 'population', 'country_code', 'admin1_name', 'admin2_name', 'geometry', 'source']\n",
    "    gdf_all_cities = pd.concat([gdf_geonames_std[cols_to_combine], gdf_worldcities_std[cols_to_combine]], ignore_index=True)\n",
    "    \n",
    "    gdf_all_cities.drop_duplicates(subset=['city_name', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "    for col in ['admin1_name', 'admin2_name']:\n",
    "        gdf_all_cities[col] = gdf_all_cities[col].apply(normalize_text).fillna('__NONE__')\n",
    "    print(f\"  Combined dataset has {len(gdf_all_cities)} unique cities.\")\n",
    "\n",
    "    # --- Step 2: Project Data and Run HDBSCAN (Unchanged) ---\n",
    "    print(\"\\nStep 2: Running HDBSCAN clustering...\")\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon_meters or 0\n",
    "    )\n",
    "    clusterer.fit(coords)\n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    print(f\"  HDBSCAN found {len(np.unique(clusterer.labels_)) - 1} clusters.\")\n",
    "\n",
    "    # --- Step 3: Identify Representatives for All Three Tiers ---\n",
    "    print(\"\\nStep 3: Identifying representatives for all three metro tiers...\")\n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    clustered_cities = gdf_all_cities[gdf_all_cities['cluster_id'] != -1]\n",
    "\n",
    "    # Tier 1: greater_metro (purely spatial)\n",
    "    idx_greater = clustered_cities.groupby('cluster_id')['population'].idxmax()\n",
    "    reps_greater = gdf_all_cities.loc[idx_greater].copy()\n",
    "    greater_map = reps_greater[['cluster_id', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_name', 'original_id': 'greater_metro_id'}\n",
    "    )\n",
    "    \n",
    "    # Tier 2: greater_metro_in_country (spatial, but respects country borders)\n",
    "    idx_greater_country = clustered_cities.groupby(['cluster_id', 'country_code'])['population'].idxmax()\n",
    "    reps_greater_country = gdf_all_cities.loc[idx_greater_country].copy()\n",
    "    greater_country_map = reps_greater_country[['cluster_id', 'country_code', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_in_country_name', 'original_id': 'greater_metro_in_country_id'}\n",
    "    )\n",
    "\n",
    "    # Tier 3: metro (most granular, respects all admin boundaries)\n",
    "    idx_local = clustered_cities.groupby(['cluster_id', 'country_code', 'admin1_name', 'admin2_name'])['population'].idxmax()\n",
    "    reps_local = gdf_all_cities.loc[idx_local].copy()\n",
    "    local_map = reps_local[['cluster_id', 'country_code', 'admin1_name', 'admin2_name', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'metro_name', 'original_id': 'metro_id'}\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Map All Tiers Back to the Main DataFrame ---\n",
    "    print(\"\\nStep 4: Merging three-tier results back into the original 'df' DataFrame...\")\n",
    "\n",
    "    gdf_all_merged = gdf_all_cities.merge(greater_map, on='cluster_id', how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(greater_country_map, on=['cluster_id', 'country_code'], how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(local_map, on=['cluster_id', 'country_code', 'admin1_name', 'admin2_name'], how='left')\n",
    "\n",
    "    # For noise/unmatched points, they represent themselves in all tiers\n",
    "    for tier_prefix in ['metro', 'greater_metro_in_country', 'greater_metro']:\n",
    "        is_unmatched = gdf_all_merged[f'{tier_prefix}_name'].isna()\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier_prefix}_name'] = gdf_all_merged.loc[is_unmatched, 'city_name']\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier_prefix}_id'] = gdf_all_merged.loc[is_unmatched, 'original_id']\n",
    "    \n",
    "    # Filter for the original data source and merge back\n",
    "    cols_to_merge = [\n",
    "        'original_id', 'metro_name', 'metro_id', 'greater_metro_in_country_name', \n",
    "        'greater_metro_in_country_id', 'greater_metro_name', 'greater_metro_id', 'source'\n",
    "    ]\n",
    "    final_cols_to_merge = gdf_all_merged[gdf_all_merged['source'] == 'geonames'][cols_to_merge]\n",
    "    final_cols_to_merge.drop_duplicates(subset=['original_id'], inplace=True)\n",
    "\n",
    "    gdf_final = gdf_geonames.merge(\n",
    "        final_cols_to_merge,\n",
    "        left_index=True,\n",
    "        right_on='original_id',\n",
    "        how='left'\n",
    "    )\n",
    "    gdf_final.drop(columns=['original_id'], inplace=True, errors='ignore')\n",
    "    print(f\"final length: {len(gdf_final)}\")\n",
    "\n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    return gdf_final\n",
    "\n",
    "final_gdf_tuned = cluster_cities_with_hdbscan_three_tier(\n",
    "    df, \n",
    "    df2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf110808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_cities_with_hdbscan_three_tier_simplified(\n",
    "    gdf_all_cities, # The function now takes one pre-merged GeoDataFrame\n",
    "    min_cluster_size=5,\n",
    "    min_samples=None,\n",
    "    cluster_selection_epsilon_meters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies a three-tiered metropolitan hierarchy using HDBSCAN on a PRE-MERGED dataset.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Three-Tier HDBSCAN Clustering Process ---\")\n",
    "\n",
    "    # --- Step 1: Prepare Data ---\n",
    "    print(\"Step 1: Preparing combined data for clustering...\")\n",
    "    gdf_all_cities = gdf_all_cities.copy()\n",
    "    \n",
    "    # Standardize column names for processing within this function\n",
    "    # This ensures consistency even if the input names are slightly different\n",
    "    gdf_all_cities.rename(columns={\n",
    "        'city_latitude': 'latitude', 'city_longitude': 'longitude',\n",
    "        'city_population': 'population', 'city_country_code': 'country_code',\n",
    "        'city_admin1_name': 'admin1_name', 'city_admin2_name': 'admin2_name'\n",
    "    }, inplace=True, errors='ignore') # ignore errors if already renamed\n",
    "\n",
    "    # Normalize admin names and fill NaNs, and add a unique ID\n",
    "    for col in ['admin1_name', 'admin2_name']:\n",
    "        gdf_all_cities[col] = gdf_all_cities[col].apply(normalize_text).fillna('')\n",
    "    gdf_all_cities['original_id'] = gdf_all_cities.index\n",
    "    print(f\"  Processing {len(gdf_all_cities)} total cities.\")\n",
    "    \n",
    "    # --- Step 2: Project Data and Run HDBSCAN ---\n",
    "    print(\"\\nStep 2: Running HDBSCAN clustering...\")\n",
    "    gdf_all_cities_proj = gdf_all_cities.to_crs(epsg=3857)\n",
    "    coords = np.array(list(zip(gdf_all_cities_proj.geometry.x, gdf_all_cities_proj.geometry.y)))\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon_meters or 0\n",
    "    )\n",
    "    clusterer.fit(coords)\n",
    "    gdf_all_cities['cluster_id'] = clusterer.labels_\n",
    "    print(f\"  HDBSCAN found {len(np.unique(clusterer.labels_)) - 1} clusters.\")\n",
    "\n",
    "    # --- Step 3: Identify Representatives for All Three Tiers ---\n",
    "    print(\"\\nStep 3: Identifying representatives for all three metro tiers...\")\n",
    "    gdf_all_cities['population'] = pd.to_numeric(gdf_all_cities['population'], errors='coerce').fillna(0)\n",
    "    clustered_cities = gdf_all_cities[gdf_all_cities['cluster_id'] != -1]\n",
    "\n",
    "    idx_greater = clustered_cities.groupby('cluster_id')['population'].idxmax()\n",
    "    reps_greater = gdf_all_cities.loc[idx_greater].copy()\n",
    "    greater_map = reps_greater[['cluster_id', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_name', 'original_id': 'greater_metro_id'}\n",
    "    )\n",
    "\n",
    "    idx_greater_country = clustered_cities.groupby(['cluster_id', 'country_code'])['population'].idxmax()\n",
    "    reps_greater_country = gdf_all_cities.loc[idx_greater_country].copy()\n",
    "    greater_country_map = reps_greater_country[['cluster_id', 'country_code', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'greater_metro_in_country_name', 'original_id': 'greater_metro_in_country_id'}\n",
    "    )\n",
    "\n",
    "    idx_local = clustered_cities.groupby(['cluster_id', 'country_code', 'admin1_name', 'admin2_name'])['population'].idxmax()\n",
    "    reps_local = gdf_all_cities.loc[idx_local].copy()\n",
    "    local_map = reps_local[['cluster_id', 'country_code', 'admin1_name', 'admin2_name', 'city_name', 'original_id']].rename(\n",
    "        columns={'city_name': 'metro_name', 'original_id': 'metro_id'}\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Map All Tiers Back to the Main DataFrame ---\n",
    "    print(\"\\nStep 4: Merging three-tier results back into the DataFrame...\")\n",
    "\n",
    "    gdf_all_merged = gdf_all_cities.merge(greater_map, on='cluster_id', how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(greater_country_map, on=['cluster_id', 'country_code'], how='left')\n",
    "    gdf_all_merged = gdf_all_merged.merge(local_map, on=['cluster_id', 'country_code', 'admin1_name', 'admin2_name'], how='left')\n",
    "\n",
    "    for tier_prefix in ['metro', 'greater_metro_in_country', 'greater_metro']:\n",
    "        is_unmatched = gdf_all_merged[f'{tier_prefix}_name'].isna()\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier_prefix}_name'] = gdf_all_merged.loc[is_unmatched, 'city_name']\n",
    "        gdf_all_merged.loc[is_unmatched, f'{tier_prefix}_id'] = gdf_all_merged.loc[is_unmatched, 'original_id']\n",
    "    \n",
    "    # The function now returns the fully merged and clustered dataframe, renaming is undone\n",
    "    final_cols = ['metro_name', 'metro_id', 'greater_metro_in_country_name', \n",
    "                  'greater_metro_in_country_id', 'greater_metro_name', 'greater_metro_id']\n",
    "    gdf_final = gdf_all_merged.drop(columns=['original_id', 'cluster_id'], errors='ignore').rename(columns={\n",
    "        'latitude': 'city_latitude', 'longitude': 'city_longitude',\n",
    "        'population': 'city_population', 'country_code': 'city_country_code',\n",
    "        'admin1_name': 'city_admin1_name', 'admin2_name': 'city_admin2_name'\n",
    "    })\n",
    "\n",
    "    # final cleanup\n",
    "    gdf_final.insert(loc=1, column='city_name_normalized', value= gdf_final[\"city_name\"].apply(normalize_text)) \n",
    "    # Normalize admin names and fill NaNs, and add a unique ID\n",
    "    for col in [\"greater_metro_name\",\t\"greater_metro_in_country_name\", \"metro_name\"]:\n",
    "        gdf_final[col] = gdf_final[col].apply(normalize_text).fillna('')\n",
    "    source = gdf_final.pop('source')\n",
    "    gdf_final.insert(len(gdf_final.columns), 'source', source)\n",
    "\n",
    "    def create_list_column(row, col1, col2):\n",
    "        \"\"\"\n",
    "        Creates a list from two columns, excluding null values.\n",
    "\n",
    "        Args:\n",
    "            row: A row of the DataFrame.\n",
    "            col1: The name of the first column.\n",
    "            col2: The name of the second column.\n",
    "\n",
    "        Returns:\n",
    "            A list containing non-null values from col1 and col2.\n",
    "        \"\"\"\n",
    "        values = row[\"alternatenames\"]\n",
    "\n",
    "        # **CRITICAL**: Only add the name if it's a non-empty string.\n",
    "        # This prevents NaN (float) values from being added to the set.\n",
    "        if isinstance(row[col1], str) and row[col1]:\n",
    "            values.append(row[col1])\n",
    "        if isinstance(row[col2], str) and row[col2]:\n",
    "            values.append(row[col2])\n",
    "        \n",
    "        return list(set(values))\n",
    "\n",
    "    gdf_final['alternatenames'] = gdf_final.apply(lambda row: create_list_column(row, 'city_name', 'city_name_normalized'), axis=1)\n",
    "\n",
    "    print(len(gdf_final))\n",
    "\n",
    "    print(\"\\n--- Process Complete! ---\")\n",
    "    return gdf_final\n",
    "\n",
    "final_gdf_tuned = cluster_cities_with_hdbscan_three_tier_simplified(\n",
    "    merged_gdf \n",
    ")\n",
    "\n",
    "# 3. View the results\n",
    "print(f\"Final DataFrame has {len(final_gdf_tuned)} entries.\")\n",
    "final_gdf_tuned.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
